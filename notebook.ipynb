{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-12T14:22:41.466428Z",
     "start_time": "2024-06-12T14:22:38.940982Z"
    }
   },
   "source": [
    "#Imports\n",
    "from io import BytesIO\n",
    "import os\n",
    "import open3d as o3d\n",
    "import random\n",
    "import requests\n",
    "import tarfile\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "from scipy.spatial.distance import cdist, pdist, squareform"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T14:22:41.484468Z",
     "start_time": "2024-06-12T14:22:41.466680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def gromov_wasserstein(pc1: np.ndarray, pc2: np.ndarray) -> float:\n",
    "    def dist_ecc_fast(ecc, u):\n",
    "        return (np.mean(ecc <= u))\n",
    "\n",
    "    out = 0\n",
    "    # Konvertiere die Punktwolken in NumPy-Arrays\n",
    "    pc1 = np.asarray(pc1.points)\n",
    "    pc2 = np.asarray(pc2.points)\n",
    "\n",
    "    # Reshape input matrices if necessary\n",
    "    if pc1.ndim == 1:\n",
    "        pc1 = pc1.reshape(-1, 1)\n",
    "    if pc2.ndim == 1:\n",
    "        pc2 = pc2.reshape(-1, 1)\n",
    "\n",
    "    ecc1 = squareform(pdist(pc1)).mean(0)\n",
    "    ecc2 = squareform(pdist(pc2)).mean(0)\n",
    "    unique_ecc = np.unique(np.concatenate((ecc1, ecc2)))\n",
    "    for i in range(unique_ecc.shape[0] - 1):\n",
    "        u = unique_ecc[i]\n",
    "        out += (unique_ecc[i + 1] - unique_ecc[i]) * np.abs(dist_ecc_fast(ecc1, u) - dist_ecc_fast(ecc2, u))\n",
    "\n",
    "    return (0.5 * out)"
   ],
   "id": "7e1568af12c11b07",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T14:22:42.128861Z",
     "start_time": "2024-06-12T14:22:42.110124Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def chamfer_distance(pc1: np.ndarray, pc2: np.ndarray) -> float:\n",
    "    dist = cdist(pc1, pc2)\n",
    "    ch_dist = (np.min(dist, axis=1).mean() + np.min(dist, axis=0).mean()) / 2\n",
    "    return ch_dist"
   ],
   "id": "d94821b1effd38a5",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T14:22:42.951866Z",
     "start_time": "2024-06-12T14:22:42.931925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def average_ratio(pc1: np.ndarray, pc2: np.ndarray, Dist_list: list) -> float:\n",
    "    d = cdist(pc1, pc2)\n",
    "    d0 = d.min(0)\n",
    "    d1 = d.min(1)\n",
    "\n",
    "    avr = 0\n",
    "    for i, dist in enumerate(Dist_list):\n",
    "        avr += (i + 1) * ((d1 <= dist).sum() / pc1.shape[0] + (d0 <= dist).sum() / pc2.shape[0])\n",
    "    return avr / (len(Dist_list) ** 2 + len(Dist_list))"
   ],
   "id": "53c1b50f63af67ab",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T14:22:43.733326Z",
     "start_time": "2024-06-12T14:22:43.719613Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_pcd_from_mesh(mesh):\n",
    "    mesh.compute_vertex_normals()\n",
    "    o3d.visualization.draw_geometries([mesh])\n",
    "    # distribute dots evenly on the surface\n",
    "    return mesh.sample_points_uniformly(500)"
   ],
   "id": "77f3497eebb98499",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T14:22:44.566835Z",
     "start_time": "2024-06-12T14:22:44.549768Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_model(link, path):\n",
    "    # http://ycb-benchmarks.s3-website-us-east-1.amazonaws.com/\n",
    "    response = requests.get(link)\n",
    "    tgz_data = BytesIO(response.content)\n",
    "    # set the current working directory to the script's directory\n",
    "    script_directory = os.path.dirname(os.path.abspath(__file__))\n",
    "    os.chdir(script_directory)\n",
    "    with tarfile.open(fileobj=tgz_data, mode=\"r:gz\") as tar_ref:\n",
    "        tar_ref.extractall(script_directory)\n",
    "    # join paths\n",
    "    model_path = os.path.join(script_directory, path, \"clouds\", \"merged_cloud.ply\")\n",
    "    # load pointcloud\n",
    "    pcd = o3d.io.read_point_cloud(model_path)\n",
    "    return pcd"
   ],
   "id": "7a14771974f89559",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T14:22:45.521782Z",
     "start_time": "2024-06-12T14:22:45.507990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_cad_model(model):\n",
    "    # load model generated in freecad\n",
    "    return o3d.io.read_point_cloud(model)"
   ],
   "id": "268acea18c088fe8",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T14:22:46.296068Z",
     "start_time": "2024-06-12T14:22:46.279562Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def visualize_model(model):\n",
    "    o3d.visualization.draw_geometries([model])"
   ],
   "id": "a6cb10deb5b2cada",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T14:22:47.133148Z",
     "start_time": "2024-06-12T14:22:47.125041Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_num_points(model):\n",
    "    print(len(model.points))"
   ],
   "id": "b24f412aa7c9f798",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T14:22:48.188468Z",
     "start_time": "2024-06-12T14:22:48.167696Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_pointcloud_from_coordinates(coordinates):\n",
    "    # create point cloud with coordinates\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(coordinates)\n",
    "    return pcd"
   ],
   "id": "9d07c2e658e06523",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T14:22:49.257245Z",
     "start_time": "2024-06-12T14:22:49.249181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_coordinates(model):\n",
    "    coordinates = [list(point) for point in model.points]\n",
    "    # print(coordinates[:50])\n",
    "    return coordinates"
   ],
   "id": "dcdc0ec299624eba",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T14:22:50.285584Z",
     "start_time": "2024-06-12T14:22:50.268982Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def random_downsampling(model, endpoints):\n",
    "    # get coordinates of the models\n",
    "    coordinates = get_coordinates(model)\n",
    "    # select random points for downsampling\n",
    "    for i in range(len(coordinates) - endpoints):\n",
    "        rannumb = random.randint(0, len(coordinates) - 1)\n",
    "        del coordinates[rannumb]\n",
    "    point_cloud = create_pointcloud_from_coordinates(coordinates)\n",
    "    return point_cloud"
   ],
   "id": "2052f3d3ed6ad35a",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T14:22:51.714580Z",
     "start_time": "2024-06-12T14:22:51.696077Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def farthest_point_sampling(model, num_points_keep):\n",
    "    coordinates = np.array(get_coordinates(model))\n",
    "    retVal = []\n",
    "    # to make runs comparable\n",
    "    random.seed(13)\n",
    "    # generate \"random\" int\n",
    "    randint = random.randint(0, len(coordinates) - 1)\n",
    "    # select random point from model\n",
    "    retVal.append(coordinates[randint])\n",
    "    # delete chosen point from original model after it was added to the downsampled cloud\n",
    "    coordinates = np.delete(coordinates, randint, axis=0)\n",
    "    while len(retVal) < num_points_keep:\n",
    "        # Berechne die euklidischen Distanzen der ausgewählten Punkte zu den verbleibenden Punkten\n",
    "        eucl_distances = distance.cdist(retVal, coordinates, 'euclidean')\n",
    "        # Finden Sie den Punkt mit der größten Mindestdistanz\n",
    "        min_mindist = np.min(eucl_distances, axis=0)\n",
    "        # Finden Sie den Index des Punktes mit der größten Mindestdistanz\n",
    "        max_min_distance_index = np.argmax(min_mindist)\n",
    "        # Fügen Sie den am weitesten entfernten Punkt der Liste hinzu\n",
    "        retVal.append(coordinates[max_min_distance_index])\n",
    "        # Entfernen Sie den ausgewählten Punkt aus den verbleibenden Koordinaten\n",
    "        coordinates = np.delete(coordinates, max_min_distance_index, axis=0)\n",
    "    return create_pointcloud_from_coordinates(np.array(retVal))"
   ],
   "id": "c93a96564378e9f4",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T14:22:52.479587Z",
     "start_time": "2024-06-12T14:22:52.460935Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# built in function von open3d?\n",
    "def radius_outlier_removal_call(model):\n",
    "    return model.remove_radius_outlier(nb_points=5, radius=0.05)"
   ],
   "id": "42dd39bb15f7e3e1",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T14:22:53.018106Z",
     "start_time": "2024-06-12T14:22:53.000155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# add noise to pointcloud\n",
    "def add_noise(model, noisiness):\n",
    "    points = np.asarray(model.points)\n",
    "    noise = np.random.normal(0, noisiness, size=points.shape)\n",
    "    noisy_points = points + noise\n",
    "\n",
    "    noisy_pc = o3d.geometry.PointCloud()\n",
    "    noisy_pc.points = o3d.utility.Vector3dVector(noisy_points)\n",
    "    return noisy_pc"
   ],
   "id": "4b8175616d52ffb4",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T14:22:54.153995Z",
     "start_time": "2024-06-12T14:22:54.137671Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# with median -> aggregation method as parameter??\n",
    "def create_voxel_grid(model, voxel_size):\n",
    "    model_points = np.array(get_coordinates(model))\n",
    "    min_bound = np.min(model_points, axis=0)\n",
    "    max_bound = np.max(model_points, axis=0)\n",
    "\n",
    "    dimensions = np.ceil((max_bound - min_bound) / voxel_size).astype(int)\n",
    "\n",
    "    voxelgrid = np.zeros(dimensions)\n",
    "\n",
    "    for point in model_points:\n",
    "        voxel_coordinates = ((point - min_bound) / voxel_size).astype(int)\n",
    "        # -1 needed in order to avoid index out of bounds\n",
    "        voxelgrid[tuple(voxel_coordinates - 1)] += 1\n",
    "    # convert voxelgrid to open3d Voxelgrid\n",
    "    o3d_voxelgrid = o3d.geometry.VoxelGrid.create_from_point_cloud(input=model, voxel_size=voxel_size)\n",
    "    #o3d.visualization.draw_geometries([o3d_voxelgrid])\n",
    "    return o3d_voxelgrid\n",
    "\n",
    "\n",
    "def voxel_filter(model, voxelgrid, voxel_size):\n",
    "    # list where downsampled points will be saved\n",
    "    downsampled_points = []\n",
    "    # iterate over all voxel in the voxelgrid\n",
    "    for voxel in voxelgrid.get_voxels():\n",
    "        # get bounds of the voxel\n",
    "        downsampled_points.extend(is_point_in_voxel(model, voxelgrid, voxel, voxel_size))\n",
    "    downsampled_points = np.asarray(downsampled_points)\n",
    "    return o3d.utility.Vector3dVector(downsampled_points)\n",
    "\n",
    "\n",
    "def aggregate_points(points):\n",
    "    # Aggregate the points by averaging, taking into account the z coordinate\n",
    "    if len(points) == 0:\n",
    "        return points\n",
    "    aggregated_points = []\n",
    "    aggregated_points.append(np.mean(points, axis=0))\n",
    "    return aggregated_points\n",
    "\n",
    "\n",
    "def is_point_in_voxel(model, voxelgrid, voxel, voxel_size):\n",
    "    # get center point and see whether a point lies within the given distance/2 of the voxel size from the center\n",
    "    voxel_center = voxelgrid.get_voxel_center_coordinate(voxel.grid_index)\n",
    "    points_in_voxel = []\n",
    "    half_size = voxel_size / 2.0\n",
    "    # Überprüfe, welche Punkte innerhalb des Voxels liegen\n",
    "    for point in model.points:\n",
    "        if np.all(np.abs(point - voxel_center) <= half_size):\n",
    "            points_in_voxel.append(point)\n",
    "    points_in_voxel = aggregate_points(points_in_voxel)\n",
    "    # print(points_in_voxel)\n",
    "    return points_in_voxel\n",
    "\n",
    "def create_points_from_voxel(voxel_model):\n",
    "    # Vektoren in Numpy Array konvertieren\n",
    "    vector_array = np.asarray(voxel_model)\n",
    "    \n",
    "    # Open3D Punktewolke erstellen\n",
    "    point_cloud = o3d.geometry.PointCloud()\n",
    "    point_cloud.points = o3d.utility.Vector3dVector(vector_array)\n",
    "    \n",
    "    return point_cloud\n"
   ],
   "id": "d80e628c3ec6ce94",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T14:22:56.851448Z",
     "start_time": "2024-06-12T14:22:56.830933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def point_cloud_to_ply(point_cloud, file_name): \n",
    "    # safe downsampled point cloud as ply data\n",
    "    file_name = \"point_cloud_images/\"+file_name+\".ply\"\n",
    "    if os.path.exists(\"point_cloud_images/\"+file_name):\n",
    "        os.remove(file_name)\n",
    "    o3d.io.write_point_cloud(file_name, o3d.geometry.PointCloud(point_cloud.points))"
   ],
   "id": "efa529414d46c342",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T14:22:59.135890Z",
     "start_time": "2024-06-12T14:22:59.116970Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import logging\n",
    "# Logging\n",
    "logging.basicConfig(filename='downsampling.log', level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "\n",
    "# Pfad zum Speichern der Bilder\n",
    "output_dir = 'point_cloud_images'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "#except Exception as e: logging.error(f'Iteration {i+1}: Fehler aufgetreten - {e}')"
   ],
   "id": "af108f8c60310f46",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T14:23:01.113329Z",
     "start_time": "2024-06-12T14:23:00.711248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# to do lege die Bilder mit relaitven Pfad im Repo an!\n",
    "cone = load_cad_model(r\"cone.ply\")\n",
    "sphere = load_cad_model(r\"sphere.ply\")\n",
    "cube = load_cad_model(r\"cube.ply\")\n",
    "complex_cube = load_cad_model(r\"complexCube.ply\")\n",
    "complex_cone = load_cad_model(r\"hollowCone.ply\")\n",
    "complex_sphere = load_cad_model(r\"complexSphere.ply\")\n",
    "pencil = load_cad_model(r\"pencil_fein.ply\")\n",
    "# source: https://sketchfab.com/3d-models/davis-teapot-materialcleanup-547971eaf21d43f2b6cfcb6be0e7bf11\n",
    "teapot = load_cad_model(r\"teapot.ply\")\n",
    "# source: https://sketchfab.com/3d-models/book-ba04f5ac66194341bc7d437fb6c94674\n",
    "book = load_cad_model(r\"book.ply\")"
   ],
   "id": "fb44a471c057b4a8",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T14:23:01.639168Z",
     "start_time": "2024-06-12T14:23:01.615815Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from open3d.examples.open3d_example import draw_registration_result\n",
    "# Auswertung ICP\n",
    "# Transformiere die Ziel-Punktwolke zur besseren Demonstration\n",
    "# ich kann hier auch meine Matplotlib Implementierung verwenden!\n",
    "def icp_algorithm(source, target):\n",
    "    # Transformierung der Target Punktewolke\n",
    "    transformation = np.array([[0.86, 0.5, 0.1, 0.5],\n",
    "                               [-0.5, 0.86, 0.1, 0.5],\n",
    "                               [0.0, -0.1, 0.99, 0.5],\n",
    "                               [0.0, 0.0, 0.0, 1.0]])\n",
    "    target = target.transform(transformation)\n",
    "    \n",
    "    # ICP-Algorithmus ausführen\n",
    "    threshold = 0.01  # Maximale Entfernung für die Zuordnung von Punkten\n",
    "    initial_transformation = np.identity(4)  # Initiale Schätzung der Transformation\n",
    "    \n",
    "    # Open3D ICP Algorithmus\n",
    "    reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "        source, target, threshold, initial_transformation,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint())\n",
    "    \n",
    "    # Ergebnis grafisch ausgeben lassen\n",
    "    draw_registration_result(source, target, reg_p2p.transformation)\n",
    "    \n",
    "    # evaluierung wie gut der ICP lief\n",
    "    evaluation = o3d.pipelines.registration.evaluate_registration(\n",
    "    source, target, threshold, transformation)\n",
    "    print(evaluation)\n"
   ],
   "id": "acbc5ea2a52a8d36",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ergebnisse in CSV schreiben",
   "id": "f86a8f451739a5c5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T14:23:05.371296Z",
     "start_time": "2024-06-12T14:23:05.352309Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import csv\n",
    "\n",
    "def write_csv(array, filename):\n",
    "\n",
    "    # Öffne die CSV-Datei im Schreibmodus\n",
    "    with open(filename, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        for row in array:\n",
    "            writer.writerow(row)"
   ],
   "id": "201d284b520fce40",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Reproduzierbarkeit",
   "id": "ae2d3719e061ce9d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T14:26:39.797846Z",
     "start_time": "2024-06-12T14:23:13.883091Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "\n",
    "#Test für Stabilität der Ergebnisse\n",
    "# Anzahl der Wiederholungen\n",
    "# Konfiguration des Loggings\n",
    "log_filename = 'downsampling.log'\n",
    "#if os.path.exists(log_filename):\n",
    "  #  os.remove(log_filename)\n",
    "    \n",
    "logging.basicConfig(\n",
    "    filename=log_filename,\n",
    "    filemode='w',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "num_iterations = 1\n",
    "output_dir_pc = 'point_cloud_images'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "model_array = [cube] #, sphere, cone, complex_cone, complex_cube, complex_sphere, pencil, teapot, book]\n",
    "\n",
    "model_array = [cube, sphere, cone, complex_cone, complex_cube, complex_sphere, pencil, teapot, book]\n",
    "rd_clouds = [[] for _ in model_array]  # List of lists for random downsampling times\n",
    "vf_clouds = [[] for _ in model_array]  # List of lists for voxel filter times\n",
    "fp_clouds = [[] for _ in model_array]  # List of lists for farthest point sampling times\n",
    "\n",
    "rd_chamfer_distances = []\n",
    "vf_chamfer_distances = []\n",
    "fp_chamfer_distances = []\n",
    "\n",
    "# Methode Spalte, Modell Zeile ?\n",
    "# [][][]    \n",
    "# [][][]\n",
    "\n",
    "\n",
    "for model in model_array:\n",
    "    for i in range(num_iterations):\n",
    "        try:\n",
    "                #random downsampling\n",
    "                method = \"random_downsampling\"\n",
    "                start = time.time()\n",
    "                rd = random_downsampling(model, int(len(model.points)/10 * 4))\n",
    "                end = time.time()\n",
    "                elapsed_time = end - start\n",
    "                logging.info(f'Random Downsampling - Iteration {i+1}: Downsampling durchgeführt, verbleibende Punkte: {len(rd.points)},      Rechenzeit: {elapsed_time:.4f} Sekunden')\n",
    "                # speichern der Punktewolke im Array\n",
    "                rd_clouds[i].append(rd.points)\n",
    "                \n",
    "                # voxelgrid\n",
    "                method = \"voxelgrid filter\"\n",
    "                start = time.time()\n",
    "                vx_grid = create_voxel_grid(model, 0.2)\n",
    "                vx = voxel_filter(model, vx_grid, 0.7)\n",
    "                end = time.time()\n",
    "                elapsed_time = end - start\n",
    "                logging.info(f'Voxel Downsampling - Iteration {i+1}: Downsampling durchgeführt, verbleibende Punkte: {len(vx)},      Rechenzeit: {elapsed_time:.4f} Sekunden')\n",
    "                # speichern der Punktewolke im Array\n",
    "                vf_clouds[i].append(vx.points)\n",
    "                print(elapsed_time)\n",
    "                # farthest point downsampling\n",
    "                method = \"farthest point downsampling\"\n",
    "                start = time.time()\n",
    "                fp= farthest_point_sampling(model,int(len(model.points)/10 * 4))\n",
    "                end = time.time()\n",
    "                elapsed_time = end - start\n",
    "                logging.info(f'Farthest Point Downsampling - Iteration {i+1}: Downsampling durchgeführt, verbleibende Punkte: {len(fp.points)}, Rechenzeit: {elapsed_time:.4f} Sekunden')\n",
    "                # speichern der Punktewolke im Array\n",
    "                fp_clouds[i].append(fp.points)\n",
    "                print(elapsed_time)\n",
    "                \n",
    "                # Random Downsampling\n",
    "                rd_chamfer_distances.append(chamfer_distance(rd,model.points))\n",
    "                # Voxelgrid Filter\n",
    "                vf_chamfer_distances.append(chamfer_distance(vx,model.points))\n",
    "                # Farthest Point Downsampling\n",
    "                fp_chamfer_distances.append(chamfer_distance(fp,model.points))\n",
    "                    \n",
    "        except Exception as e:\n",
    "            logging.error(f'Iteration {i+1} , Methode {method}: Fehler aufgetreten- {e}')\n",
    "\n",
    "logging.info('Alle Iterationen abgeschlossen.') \n",
    "write_csv(rd_chamfer_distances,\"rd_chamfer.csv\")\n",
    "write_csv(vf_chamfer_distances,\"vf_chamfer.csv\")\n",
    "write_csv(fp_chamfer_distances,\"fp_chamfer.csv\")"
   ],
   "id": "81adc1d850b8c8ba",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[22], line 54\u001B[0m\n\u001B[0;32m     52\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m     53\u001B[0m vx_grid \u001B[38;5;241m=\u001B[39m create_voxel_grid(model, \u001B[38;5;241m0.2\u001B[39m)\n\u001B[1;32m---> 54\u001B[0m vx \u001B[38;5;241m=\u001B[39m \u001B[43mvoxel_filter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvx_grid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.7\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     55\u001B[0m end \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m     56\u001B[0m elapsed_time \u001B[38;5;241m=\u001B[39m end \u001B[38;5;241m-\u001B[39m start\n",
      "Cell \u001B[1;32mIn[16], line 27\u001B[0m, in \u001B[0;36mvoxel_filter\u001B[1;34m(model, voxelgrid, voxel_size)\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;66;03m# iterate over all voxel in the voxelgrid\u001B[39;00m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m voxel \u001B[38;5;129;01min\u001B[39;00m voxelgrid\u001B[38;5;241m.\u001B[39mget_voxels():\n\u001B[0;32m     26\u001B[0m     \u001B[38;5;66;03m# get bounds of the voxel\u001B[39;00m\n\u001B[1;32m---> 27\u001B[0m     downsampled_points\u001B[38;5;241m.\u001B[39mextend(\u001B[43mis_point_in_voxel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvoxelgrid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvoxel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvoxel_size\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m     28\u001B[0m downsampled_points \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(downsampled_points)\n\u001B[0;32m     29\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m o3d\u001B[38;5;241m.\u001B[39mutility\u001B[38;5;241m.\u001B[39mVector3dVector(downsampled_points)\n",
      "Cell \u001B[1;32mIn[16], line 48\u001B[0m, in \u001B[0;36mis_point_in_voxel\u001B[1;34m(model, voxelgrid, voxel, voxel_size)\u001B[0m\n\u001B[0;32m     46\u001B[0m \u001B[38;5;66;03m# Überprüfe, welche Punkte innerhalb des Voxels liegen\u001B[39;00m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m point \u001B[38;5;129;01min\u001B[39;00m model\u001B[38;5;241m.\u001B[39mpoints:\n\u001B[1;32m---> 48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m np\u001B[38;5;241m.\u001B[39mall(\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mabs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpoint\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mvoxel_center\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m<\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mhalf_size\u001B[49m):\n\u001B[0;32m     49\u001B[0m         points_in_voxel\u001B[38;5;241m.\u001B[39mappend(point)\n\u001B[0;32m     50\u001B[0m points_in_voxel \u001B[38;5;241m=\u001B[39m aggregate_points(points_in_voxel)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Visualisierung\n",
    "rd_chamfer_distances = [\n",
    "    [  # Modell 1\n",
    "        [ch_dist_1_2, ch_dist_1_3, ch_dist_1_4],  # Iteration 1 (zu Iteration 2, 3, 4)\n",
    "        [ch_dist_2_3, ch_dist_2_4],               # Iteration 2 (zu Iteration 3, 4)\n",
    "        [ch_dist_3_4]                             # Iteration 3 (zu Iteration 4)\n",
    "    ],\n",
    "    [  # Modell 2\n",
    "        [ch_dist_1_2, ch_dist_1_3, ch_dist_1_4],\n",
    "        [ch_dist_2_3, ch_dist_2_4],\n",
    "        [ch_dist_3_4]\n",
    "    ],\n",
    "    [  # Modell 3\n",
    "        [ch_dist_1_2, ch_dist_1_3, ch_dist_1_4],\n",
    "        [ch_dist_2_3, ch_dist_2_4],\n",
    "        [ch_dist_3_4]\n",
    "    ]\n",
    "]\n"
   ],
   "id": "75a23c127e3b319f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Auswertung Chamfer Distanz Random Downsampling",
   "id": "aaa937d462a2d974"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "iterations = list(range(1, num_iterations + 1))\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(iterations, rd_chamfer_distances, label='Chamfer Distances Random Downsampling')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Chamfer Distance')\n",
    "plt.title('Chamfer Distance for Random Downsampling over Iterations')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "80cf7ce7ee7395ca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "iterations = list(range(1, num_iterations + 1))\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(iterations, vf_chamfer_distances, label='Chamfer Distances Voxel Grid Filter')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Chamfer Distance')\n",
    "plt.title('Chamfer Distance for Voxel Grid Filter over Iterations')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "80f3ef26c9217051",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "iterations = list(range(1, num_iterations + 1))\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(iterations, rd_chamfer_distances, label='Chamfer Distances Farthest Point Downsampling')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Chamfer Distance')\n",
    "plt.title('Chamfer Distance for Farthest Point Downsampling over Iterations')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "25e9a95818161f0a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "20e5bd80842be77"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rd_avg_ratio = []\n",
    "vf_avg_ratio = []\n",
    "fp_avg_ratio = []\n",
    "\n",
    "for model_index, model in enumerate(model_array):\n",
    "    for i in range(num_iterations):\n",
    "        try:\n",
    "            # mit dem originalen Model vergeleichen\n",
    "            original_pc = model\n",
    "\n",
    "            # Random Downsampling\n",
    "            rd_avg_ratio.append(average_ratio(rd_clouds[model_index][i], original_pc),)\n",
    "\n",
    "            # Voxelgrid Filter\n",
    "            vf_avg_ratio.append(chamfer_distance(vf_clouds[model_index][i], original_pc),)\n",
    "\n",
    "            # Farthest Point Downsampling\n",
    "            fp_avg_ratio.append(chamfer_distance(fp_clouds[model_index][i], original_pc),)\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f'Chamfer Distance - Model {model_index+1} - Iteration {i+1}: Fehler aufgetreten - {e}')\n",
    "\n",
    "write_csv(rd_avg_ratio,\"rd_avg_ratio.csv\")\n",
    "write_csv(vf_avg_ratio,\"vf_avg_ratio.csv\")\n",
    "write_csv(fp_avg_ratio,\"fp_avg_ratio.csv\")"
   ],
   "id": "1a4d3856e7a1e07f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "2d9862ecfcf8bacc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rd_wasserstein = []\n",
    "vf_wasserstein = []\n",
    "fp_wasserstein = []\n",
    "\n",
    "for model_index, model in enumerate(model_array):\n",
    "    for i in range(num_iterations):\n",
    "        try:\n",
    "            # mit dem originalen Model vergeleichen\n",
    "            original_pc = model\n",
    "\n",
    "            # Random Downsampling\n",
    "            rd_wasserstein.append(gromov_wasserstein(rd_clouds[model_index][i], original_pc))\n",
    "\n",
    "            # Voxelgrid Filter\n",
    "            vf_wasserstein.append(gromov_wasserstein(vf_clouds[model_index][i], original_pc))\n",
    "\n",
    "            # Farthest Point Downsampling\n",
    "            fp_wasserstein.append(gromov_wasserstein(fp_clouds[model_index][i], original_pc))\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f'Chamfer Distance - Model {model_index+1} - Iteration {i+1}: Fehler aufgetreten - {e}')\n",
    "\n",
    "write_csv(rd_wasserstein,\"rd_wasserstein.csv\")\n",
    "write_csv(vf_wasserstein,\"vf_wasserstein.csv\")\n",
    "write_csv(fp_wasserstein,\"fp_wasserstein.csv\")"
   ],
   "id": "78525b11290818ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Laufzeittest",
   "id": "e0f9402fc2f869a6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rd_times = [[] for _ in model_array]  # List of lists for random downsampling times\n",
    "vf_times = [[] for _ in model_array]  # List of lists for voxel filter times\n",
    "fp_times = [[] for _ in model_array]  # List of lists for farthest point sampling times\n",
    "\n",
    "# Methode Spalte, Modell Zeile ?\n",
    "# [][][]    \n",
    "# [][][]\n",
    "\n",
    "for round in range(25):\n",
    "    for i, model in enumerate(model_array):\n",
    "        \n",
    "        try: \n",
    "            # random downsampling\n",
    "            method = \"random downsampling\"\n",
    "            start = time.time()\n",
    "            rd = random_downsampling(model, int(len(model.points)/10 * 4))\n",
    "            end = time.time()\n",
    "            elapsed_time = end - start\n",
    "            rd_times[i].append(elapsed_time)    \n",
    "            \n",
    "            # voxelgrid filter\n",
    "            method = \"voxelgrid filter downsampling\"\n",
    "            start = time.time()\n",
    "            vx_grid = create_voxel_grid(model, 0.2)\n",
    "            vx = voxel_filter(model, vx_grid, 0.7)\n",
    "            end = time.time()\n",
    "            elapsed_time = end - start\n",
    "            vf_times[i].append(elapsed_time)\n",
    "            \n",
    "            # farthest point downsampling\n",
    "            method = \"farthest point downsampling\"\n",
    "            start = time.time()\n",
    "            fp= farthest_point_sampling(model,int(len(model.points)/10 * 4))\n",
    "            end = time.time()\n",
    "            fp_pc = o3d.geometry.PointCloud()\n",
    "            fp_pc.points = o3d.utility.Vector3dVector(np.asarray(fp.points))\n",
    "            elapsed_time = end - start\n",
    "            fp_times[i].append(elapsed_time)  # Add the time to the corresponding model's list\n",
    "        except Exception as e:\n",
    "            print('Methode:' + method + ' Iteration ' + i + ' Fehlermeldung: ' + e)\n",
    "\n",
    "write_csv(rd_clouds,\"rd_times.csv\")\n",
    "write_csv(vf_clouds,\"vf_times.csv\")\n",
    "write_csv(fp_clouds,\"fp_times.csv\")"
   ],
   "id": "30bb7091f0189d22",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plot out of times for each model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Boxplot erstellen\n",
    "plt.boxplot(rd_times, labels=(\"cube\")) #, \"sphere\", \"cone\", \"complex_cone\", \"complex_cube\", \"complex_sphere\", \"pencil\", \"teapot\", \"book\"))\n",
    "plt.title('Boxplot der Modelle für Random Donsampling')\n",
    "plt.xlabel('Modelle')\n",
    "plt.ylabel('Zeit')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "f997b8f9006ff366",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plot out of times for each model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for times in vf_times:\n",
    "    print(times)\n",
    "\n",
    "# Boxplot erstellen\n",
    "plt.boxplot(vf_times, labels=(\"cube\")) #, \"sphere\", \"cone\", \"complex_cone\", \"complex_cube\", \"complex_sphere\", \"pencil\", \"teapot\", \"book\"))\n",
    "plt.title('Boxplot der Modelle für Voxelfilter Donsampling')\n",
    "plt.xlabel('Modelle')\n",
    "plt.ylabel('Zeit')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "cd659f3f5902a5c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plot out of times for each model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for times in fp_times:\n",
    "    print(times)\n",
    "    \n",
    "# Boxplot erstellen\n",
    "plt.boxplot(fp_times, labels=(\"cube\")) #, \"sphere\", \"cone\", \"complex_cone\", \"complex_cube\", \"complex_sphere\", \"pencil\", \"teapot\", \"book\"))\n",
    "plt.title('Boxplot der Modelle für Farthest Point Donsampling')\n",
    "plt.xlabel('Modelle')\n",
    "plt.ylabel('Zeit')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "cec6e0364eae53c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "ICP Tests",
   "id": "df7ee548165a3048"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_array = [cube, sphere, cone, complex_cone, complex_cube, complex_sphere, pencil, teapot, book]\n",
    "rd_icp = [[] for _ in model_array]  # List of lists for random downsampling times\n",
    "vf_icp = [[] for _ in model_array]  # List of lists for voxel filter times\n",
    "fp_icp = [[] for _ in model_array]  # List of lists for farthest point sampling times\n",
    "\n",
    "# Methode Spalte, Modell Zeile ?\n",
    "# [][][]    \n",
    "# [][][]\n",
    "\n",
    "for round in range(num_iterations):\n",
    "    for i, model in enumerate(model_array):\n",
    "        try:\n",
    "             # random downsampling\n",
    "            method = \"random downsampling\"\n",
    "            model_rd= random_downsampling(model, int(len(model.points)/10 * 4))\n",
    "            model_rd_pc = o3d.geometry.PointCloud()\n",
    "            model_rd_pc.points = o3d.utility.Vector3dVector(np.asarray(model_rd.points))\n",
    "            rd_icp[i].append(icp_algorithm(model, model_rd_pc) )    \n",
    "            \n",
    "            # voxel grid filter\n",
    "            method = \"voxelgrid filter downsampling\"\n",
    "            model_voxel_grid = create_voxel_grid(model, 0.2)\n",
    "            model_voxel_pc = o3d.geometry.PointCloud()\n",
    "            model_voxel_pc.points = voxel_filter(model, model_voxel_grid,0.2)\n",
    "            vf_icp[i].append(icp_algorithm(model_voxel_pc,model))    \n",
    "            \n",
    "            # farthest point downsampling\n",
    "            method = \"farthest point downsampling\"\n",
    "            model_fp = farthest_point_sampling(model,int(len(model.points)/10 * 4))\n",
    "            model_fp_pc = o3d.geometry.PointCloud()\n",
    "            model_fp_pc.points = o3d.utility.Vector3dVector(np.asarray(model_fp.points))\n",
    "            vf_icp[i].append(icp_algorithm(model, model_fp_pc))    \n",
    "            \n",
    "        except Exception as e:\n",
    "            print('Methode:' + method + ' Iteration ' + i + ' Fehlermeldung: ' + e)\n",
    "            \n",
    "write_csv(rd_icp,\"rd_icp\")\n",
    "write_csv(vf_icp,\"vf_icp\")\n",
    "write_csv(fp_icp,\"fp_icp\")"
   ],
   "id": "f2ae2791168b938f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Plot ICP Random Downsampling",
   "id": "e2f7ca6684e7cdac"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plot out of icp for each model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for icp in rd_icp:\n",
    "    print(icp)\n",
    "    \n",
    "# Boxplot erstellen\n",
    "plt.boxplot(rd_icp, labels=(\"cube\"))#, \"sphere\", \"cone\", \"complex_cone\", \"complex_cube\", \"complex_sphere\", \"pencil\", \"teapot\", \"book\"))\n",
    "plt.title('Boxplot der Modelle für Random Point Downsampling')\n",
    "plt.xlabel('Modelle')\n",
    "plt.ylabel('Zeit')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "8bbb3dc49a946c9e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Plot ICP Voxel Grid Filter",
   "id": "1ca018bebdb0f0d1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plot out of icp for each model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for icp in vf_icp:\n",
    "    print(icp)\n",
    "    \n",
    "# Boxplot erstellen\n",
    "plt.boxplot(rd_icp, labels=(\"cube\")) #, \"sphere\", \"cone\", \"complex_cone\", \"complex_cube\", \"complex_sphere\", \"pencil\", \"teapot\", \"book\"))\n",
    "plt.title('Boxplot der Modelle für Voxel Grid Filter Downsampling')\n",
    "plt.xlabel('Modelle')\n",
    "plt.ylabel('Zeit')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "bf34e9244c803460",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Plot Farthest Point Downsampling",
   "id": "44f6b0edb58b229e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plot out of icp for each model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for icp in fp_icp:\n",
    "    print(icp)\n",
    "    \n",
    "# Boxplot erstellen\n",
    "plt.boxplot(rd_icp, labels=(\"cube\"))#, \"sphere\", \"cone\", \"complex_cone\", \"complex_cube\", \"complex_sphere\", \"pencil\", \"teapot\", \"book\"))\n",
    "plt.title('Boxplot der Modelle für Farthest Point Downsampling')\n",
    "plt.xlabel('Modelle')\n",
    "plt.ylabel('Zeit')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "34815721cade5b3c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Noisiness test basic models",
   "id": "b3915e0c231b90ca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_array = [sphere,cube,cone]\n",
    "model_names = [\"sphere\",\"cube\",\"cone\"]\n",
    "for index, model in enumerate(model_array):\n",
    "    # create noisy pointclouds\n",
    "    noisy_model= add_noise(model,1.3)\n",
    "    visualize_model(noisy_model)\n",
    "    \n",
    "    # Random Downsampling\n",
    "    rd_noisy = random_downsampling(noisy_model,int(len(noisy_model.points)/10 * 4))\n",
    "    point_cloud_to_ply(\"noisy_rd_\"+model_names[index]+\".ply\",rd_noisy)\n",
    "\n",
    "    # Voxel Grid Filter\n",
    "    noisy_model_grid = create_voxel_grid(noisy_model, 0.2)\n",
    "    noisy_model_voxel_pc = o3d.geometry.PointCloud()\n",
    "    noisy_model_voxel_pc.points = voxel_filter(noisy_model, noisy_model_grid,0.2)\n",
    "    point_cloud_to_ply(\"noisy_vf_\"+model_names[index]+\".ply\",noisy_model_voxel_pc)\n",
    "    \n",
    "    # Farthest Point Downsampling\n",
    "    noisy_model_fp = farthest_point_sampling(noisy_model,int(len(noisy_model.points)/10 * 4))\n",
    "    noisy_model_fp_pc = o3d.geometry.PointCloud()\n",
    "    noisy_model_fp_pc.points = o3d.utility.Vector3dVector(np.asarray(noisy_model_fp.points))\n",
    "    point_cloud_to_ply(\"noisy_fp_\"+model_names[index]+\".ply\",noisy_model_fp_pc)\n"
   ],
   "id": "8d66fc758daa7984",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "noisiness tests complex models",
   "id": "4614eecfb0cb5f76"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_array = [complex_sphere,complex_cube,complex_cone]\n",
    "model_names = [\"complex_sphere\",\"complex_cube\",\"complex_cone\"]\n",
    "\n",
    "for complex_model, index in enumerate(model_array):\n",
    "\n",
    "    noisy_complex_model =add_noise(complex_model,1.3)\n",
    "    visualize_model(noisy_complex_model)\n",
    "    rd_complex_noisy = random_downsampling(noisy_complex_model,int(len(noisy_complex_model.points)/10 * 4))\n",
    "    point_cloud_to_ply(rd_complex_noisy, \"noisy_rd_\"+model_names[index]+\".ply\")\n",
    "\n",
    "    noisy_complex_model_grid = create_voxel_grid(noisy_complex_model, 0.2)\n",
    "    noisy_complex_model_voxel_pc = o3d.geometry.PointCloud()\n",
    "    noisy_complex_model_voxel_pc.points = voxel_filter(noisy_complex_model, noisy_complex_model_grid,0.2)\n",
    "    point_cloud_to_ply(noisy_complex_model_voxel_pc, \"noisy_vf_\"+model_names[index]+\".ply\")\n",
    "\n",
    "    noisy_complex_model_fp = farthest_point_sampling(noisy_complex_model,int(len(noisy_complex_model.points)/10 * 4))\n",
    "    noisy_complex_model_fp_pc = o3d.geometry.PointCloud()\n",
    "    noisy_complex_model_fp_pc.points = o3d.utility.Vector3dVector(np.asarray(noisy_complex_model_fp.points))\n",
    "    point_cloud_to_ply(noisy_complex_model_fp_pc, \"noisy_fp_\"+model_names[index]+\".ply\")"
   ],
   "id": "c8bbfb52eaf0dd2d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "noisiness tests objects",
   "id": "8a7a286ea5d1bbce"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_array = [teapot,book,pencil]\n",
    "model_names = [\"teapot\",\"book\",\"pencil\"]\n",
    "\n",
    "for model_object, index in enumerate(model_array):\n",
    "        \n",
    "    # random downsampling\n",
    "    noisy_model_object = add_noise(model_object,0.1)\n",
    "    visualize_model(noisy_model_object)\n",
    "    rd_noisy = random_downsampling(noisy_model_object, int(len(noisy_model_object.points)/10 * 4))\n",
    "    point_cloud_to_ply(rd_noisy, \"noisy_rd_\"+model_names[index]+\".ply\")\n",
    "\n",
    "    # voxel grid filter\n",
    "    noisy_model_object_grid = create_voxel_grid(noisy_model_object, 0.2)\n",
    "    noisy_object_voxel_pc = o3d.geometry.PointCloud()\n",
    "    noisy_object_voxel_pc.points = voxel_filter(noisy_model_object, noisy_model_object_grid,0.2)\n",
    "    point_cloud_to_ply(noisy_object_voxel_pc, \"noisy_vf_\"+model_names[index]+\".ply\")\n",
    "\n",
    "    # farthest point downsampling\n",
    "    noisy_model_object_fp = farthest_point_sampling(noisy_model_object,int(len(noisy_model_object.points)/10 * 4))\n",
    "    noisy_model_object_fp_pc = o3d.geometry.PointCloud()\n",
    "    noisy_model_object_fp_pc.points = o3d.utility.Vector3dVector(np.asarray(noisy_model_object_fp.points))\n",
    "    point_cloud_to_ply(noisy_model_object_fp_pc, \"noisy_fp_\"+model_names[index]+\".ply\")"
   ],
   "id": "979984132ccf6e65",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "a13a509dd712e465"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
