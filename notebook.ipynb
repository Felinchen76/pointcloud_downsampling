{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-14T15:46:37.188690Z",
     "start_time": "2024-06-14T15:46:37.156999Z"
    }
   },
   "source": [
    "#Imports\n",
    "from io import BytesIO\n",
    "import os\n",
    "import open3d as o3d\n",
    "import random\n",
    "import requests\n",
    "import tarfile\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "from scipy.spatial.distance import cdist, pdist, squareform"
   ],
   "outputs": [],
   "execution_count": 164
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T15:46:37.322995Z",
     "start_time": "2024-06-14T15:46:37.299063Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def gromov_wasserstein(pc1: np.ndarray, pc2: np.ndarray) -> float:\n",
    "    def dist_ecc_fast(ecc, u):\n",
    "        return (np.mean(ecc <= u))\n",
    "\n",
    "    out = 0\n",
    "    # Konvertiere die Punktwolken in NumPy-Arrays\n",
    "    pc1 = np.asarray(pc1.points)\n",
    "    pc2 = np.asarray(pc2.points)\n",
    "\n",
    "    # Reshape input matrices if necessary\n",
    "    if pc1.ndim == 1:\n",
    "        pc1 = pc1.reshape(-1, 1)\n",
    "    if pc2.ndim == 1:\n",
    "        pc2 = pc2.reshape(-1, 1)\n",
    "\n",
    "    ecc1 = squareform(pdist(pc1)).mean(0)\n",
    "    ecc2 = squareform(pdist(pc2)).mean(0)\n",
    "    unique_ecc = np.unique(np.concatenate((ecc1, ecc2)))\n",
    "    for i in range(unique_ecc.shape[0] - 1):\n",
    "        u = unique_ecc[i]\n",
    "        out += (unique_ecc[i + 1] - unique_ecc[i]) * np.abs(dist_ecc_fast(ecc1, u) - dist_ecc_fast(ecc2, u))\n",
    "\n",
    "    return (0.5 * out)"
   ],
   "id": "7e1568af12c11b07",
   "outputs": [],
   "execution_count": 165
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T15:46:37.345916Z",
     "start_time": "2024-06-14T15:46:37.322995Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def chamfer_distance(pc1: np.ndarray, pc2: np.ndarray) -> float:\n",
    "    dist = cdist(pc1, pc2)\n",
    "    ch_dist = (np.min(dist, axis=1).mean() + np.min(dist, axis=0).mean()) / 2\n",
    "    return ch_dist"
   ],
   "id": "d94821b1effd38a5",
   "outputs": [],
   "execution_count": 166
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T15:46:37.365772Z",
     "start_time": "2024-06-14T15:46:37.347023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def average_ratio(pc1: np.ndarray, pc2: np.ndarray, Dist_list: list) -> float:\n",
    "    pc1 = np.asarray(pc1)\n",
    "    pc2 = np.asarray(pc2)\n",
    "    \n",
    "    d = cdist(pc1, pc2)\n",
    "    d0 = d.min(0)\n",
    "    d1 = d.min(1)\n",
    "\n",
    "    avr = 0\n",
    "    for i, dist in enumerate(Dist_list):\n",
    "        avr += (i + 1) * ((d1 <= dist).sum() / pc1.shape[0] + (d0 <= dist).sum() / pc2.shape[0])\n",
    "    return avr / (len(Dist_list) ** 2 + len(Dist_list))"
   ],
   "id": "53c1b50f63af67ab",
   "outputs": [],
   "execution_count": 167
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T15:46:37.388381Z",
     "start_time": "2024-06-14T15:46:37.365909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_pcd_from_mesh(mesh):\n",
    "    mesh.compute_vertex_normals()\n",
    "    o3d.visualization.draw_geometries([mesh])\n",
    "    # distribute dots evenly on the surface\n",
    "    return mesh.sample_points_uniformly(500)"
   ],
   "id": "77f3497eebb98499",
   "outputs": [],
   "execution_count": 168
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T15:46:37.415464Z",
     "start_time": "2024-06-14T15:46:37.389272Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_model(link, path):\n",
    "    # http://ycb-benchmarks.s3-website-us-east-1.amazonaws.com/\n",
    "    response = requests.get(link)\n",
    "    tgz_data = BytesIO(response.content)\n",
    "    # set the current working directory to the script's directory\n",
    "    script_directory = os.path.dirname(os.path.abspath(__file__))\n",
    "    os.chdir(script_directory)\n",
    "    with tarfile.open(fileobj=tgz_data, mode=\"r:gz\") as tar_ref:\n",
    "        tar_ref.extractall(script_directory)\n",
    "    # join paths\n",
    "    model_path = os.path.join(script_directory, path, \"clouds\", \"merged_cloud.ply\")\n",
    "    # load pointcloud\n",
    "    pcd = o3d.io.read_point_cloud(model_path)\n",
    "    return pcd"
   ],
   "id": "7a14771974f89559",
   "outputs": [],
   "execution_count": 169
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T15:46:37.430606Z",
     "start_time": "2024-06-14T15:46:37.416135Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_cad_model(model):\n",
    "    # load model generated in freecad\n",
    "    return o3d.io.read_point_cloud(model)"
   ],
   "id": "268acea18c088fe8",
   "outputs": [],
   "execution_count": 170
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T15:46:37.463217Z",
     "start_time": "2024-06-14T15:46:37.451530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def visualize_model(model):\n",
    "    o3d.visualization.draw_geometries([model])"
   ],
   "id": "a6cb10deb5b2cada",
   "outputs": [],
   "execution_count": 171
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T15:46:37.525322Z",
     "start_time": "2024-06-14T15:46:37.495847Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_num_points(model):\n",
    "    print(len(model.points))"
   ],
   "id": "b24f412aa7c9f798",
   "outputs": [],
   "execution_count": 172
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T15:46:37.576094Z",
     "start_time": "2024-06-14T15:46:37.551991Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_pointcloud_from_coordinates(coordinates):\n",
    "    # create point cloud with coordinates\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(coordinates)\n",
    "    return pcd"
   ],
   "id": "9d07c2e658e06523",
   "outputs": [],
   "execution_count": 173
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T15:46:37.612011Z",
     "start_time": "2024-06-14T15:46:37.587487Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_coordinates(model):\n",
    "    coordinates = [list(point) for point in model.points]\n",
    "    # print(coordinates[:50])\n",
    "    return coordinates"
   ],
   "id": "dcdc0ec299624eba",
   "outputs": [],
   "execution_count": 174
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T15:46:37.645856Z",
     "start_time": "2024-06-14T15:46:37.612011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def random_downsampling(model, endpoints):\n",
    "    # get coordinates of the models\n",
    "    coordinates = get_coordinates(model)\n",
    "    # select random points for downsampling\n",
    "    for i in range(len(coordinates) - endpoints):\n",
    "        rannumb = random.randint(0, len(coordinates) - 1)\n",
    "        del coordinates[rannumb]\n",
    "    point_cloud = create_pointcloud_from_coordinates(coordinates)\n",
    "    return point_cloud"
   ],
   "id": "2052f3d3ed6ad35a",
   "outputs": [],
   "execution_count": 175
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T15:46:37.672540Z",
     "start_time": "2024-06-14T15:46:37.646896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def farthest_point_sampling(model, num_points_keep):\n",
    "    coordinates = np.array(get_coordinates(model))\n",
    "    retVal = []\n",
    "    # to make runs comparable\n",
    "    random.seed(13)\n",
    "    # generate \"random\" int\n",
    "    randint = random.randint(0, len(coordinates) - 1)\n",
    "    # select random point from model\n",
    "    retVal.append(coordinates[randint])\n",
    "    # delete chosen point from original model after it was added to the downsampled cloud\n",
    "    coordinates = np.delete(coordinates, randint, axis=0)\n",
    "    while len(retVal) < num_points_keep:\n",
    "        # Berechne die euklidischen Distanzen der ausgewählten Punkte zu den verbleibenden Punkten\n",
    "        eucl_distances = distance.cdist(retVal, coordinates, 'euclidean')\n",
    "        # Find point with largest min Distance\n",
    "        min_mindist = np.min(eucl_distances, axis=0)\n",
    "        # Find index of point with largest min DIstance\n",
    "        max_min_distance_index = np.argmax(min_mindist)\n",
    "        # add point that is farthest away\n",
    "        retVal.append(coordinates[max_min_distance_index])\n",
    "        # delete point from coordinates list \n",
    "        coordinates = np.delete(coordinates, max_min_distance_index, axis=0)\n",
    "    return create_pointcloud_from_coordinates(np.array(retVal))"
   ],
   "id": "c93a96564378e9f4",
   "outputs": [],
   "execution_count": 176
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T15:46:37.725058Z",
     "start_time": "2024-06-14T15:46:37.705433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# built in function von open3d\n",
    "def radius_outlier_removal_call(model):\n",
    "    return model.remove_radius_outlier(nb_points=5, radius=0.05)"
   ],
   "id": "42dd39bb15f7e3e1",
   "outputs": [],
   "execution_count": 177
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T15:46:37.755225Z",
     "start_time": "2024-06-14T15:46:37.725119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# add noise to pointcloud\n",
    "def add_noise(model, noisiness):\n",
    "    points = np.asarray(model.points)\n",
    "    noise = np.random.normal(0, noisiness, size=points.shape)\n",
    "    noisy_points = points + noise\n",
    "\n",
    "    noisy_pc = o3d.geometry.PointCloud()\n",
    "    noisy_pc.points = o3d.utility.Vector3dVector(noisy_points)\n",
    "    return noisy_pc"
   ],
   "id": "4b8175616d52ffb4",
   "outputs": [],
   "execution_count": 178
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T15:46:37.793234Z",
     "start_time": "2024-06-14T15:46:37.756832Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_voxel_grid(model, voxel_size):\n",
    "    model_points = np.array(get_coordinates(model))\n",
    "    min_bound = np.min(model_points, axis=0)\n",
    "    max_bound = np.max(model_points, axis=0)\n",
    "\n",
    "    dimensions = np.ceil((max_bound - min_bound) / voxel_size).astype(int)\n",
    "\n",
    "    voxelgrid = np.zeros(dimensions)\n",
    "\n",
    "    for point in model_points:\n",
    "        voxel_coordinates = ((point - min_bound) / voxel_size).astype(int)\n",
    "        # -1 needed in order to avoid index out of bounds\n",
    "        voxelgrid[tuple(voxel_coordinates - 1)] += 1\n",
    "    # convert voxelgrid to open3d Voxelgrid\n",
    "    o3d_voxelgrid = o3d.geometry.VoxelGrid.create_from_point_cloud(input=model, voxel_size=voxel_size)\n",
    "    #o3d.visualization.draw_geometries([o3d_voxelgrid])\n",
    "    return o3d_voxelgrid\n",
    "\n",
    "\n",
    "def voxel_filter(model, voxelgrid, voxel_size):\n",
    "    # list where downsampled points will be saved\n",
    "    downsampled_points = []\n",
    "    # iterate over all voxel in the voxelgrid\n",
    "    for voxel in voxelgrid.get_voxels():\n",
    "        # get bounds of the voxel\n",
    "        downsampled_points.extend(is_point_in_voxel(model, voxelgrid, voxel, voxel_size))\n",
    "    downsampled_points = np.asarray(downsampled_points)\n",
    "    return create_pointcloud_from_coordinates(downsampled_points)\n",
    "\n",
    "\n",
    "def aggregate_points(points):\n",
    "    # Aggregate the points by averaging, taking into account the z coordinate\n",
    "    if len(points) == 0:\n",
    "        return points\n",
    "    aggregated_points = []\n",
    "    aggregated_points.append(np.mean(points, axis=0))\n",
    "    return aggregated_points\n",
    "\n",
    "\n",
    "def is_point_in_voxel(model, voxelgrid, voxel, voxel_size):\n",
    "    # get center point and see whether a point lies within the given distance/2 of the voxel size from the center\n",
    "    voxel_center = voxelgrid.get_voxel_center_coordinate(voxel.grid_index)\n",
    "    points_in_voxel = []\n",
    "    half_size = voxel_size / 2.0\n",
    "    # check, which points are lying within a voxel\n",
    "    for point in model.points:\n",
    "        if np.all(np.abs(point - voxel_center) <= half_size):\n",
    "            points_in_voxel.append(point)\n",
    "    points_in_voxel = aggregate_points(points_in_voxel)\n",
    "    # print(points_in_voxel)\n",
    "    return points_in_voxel\n",
    "\n",
    "def create_points_from_voxel(voxel_model):\n",
    "    # convert vector in numpy array\n",
    "    vector_array = np.asarray(voxel_model)\n",
    "    \n",
    "    # create o3d point cloud\n",
    "    point_cloud = o3d.geometry.PointCloud()\n",
    "    point_cloud.points = o3d.utility.Vector3dVector(vector_array)\n",
    "    \n",
    "    return point_cloud\n"
   ],
   "id": "d80e628c3ec6ce94",
   "outputs": [],
   "execution_count": 179
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T15:46:37.809014Z",
     "start_time": "2024-06-14T15:46:37.793234Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def point_cloud_to_ply(point_cloud, file_name): \n",
    "    # safe downsampled point cloud as ply data\n",
    "    file_name = \"point_cloud_images/\"+file_name+\".ply\"\n",
    "    if os.path.exists(\"point_cloud_images/\"+file_name):\n",
    "        os.remove(file_name)\n",
    "    o3d.io.write_point_cloud(file_name, o3d.geometry.PointCloud(point_cloud.points))"
   ],
   "id": "efa529414d46c342",
   "outputs": [],
   "execution_count": 180
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T15:46:37.830217Z",
     "start_time": "2024-06-14T15:46:37.809014Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import logging\n",
    "# Logging\n",
    "logging.basicConfig(filename='downsampling.log', level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "\n",
    "# path for storage\n",
    "output_dir = 'point_cloud_images'\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ],
   "id": "af108f8c60310f46",
   "outputs": [],
   "execution_count": 181
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Laden der Punktewolken",
   "id": "db51eef7e9ea26fd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T15:46:38.312755Z",
     "start_time": "2024-06-14T15:46:37.830217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cone = load_cad_model(r\"cone.ply\")\n",
    "sphere = load_cad_model(r\"sphere.ply\")\n",
    "cube = load_cad_model(r\"cube.ply\")\n",
    "complex_cube = load_cad_model(r\"complexCube.ply\")\n",
    "complex_cone = load_cad_model(r\"hollowCone.ply\")\n",
    "complex_sphere = load_cad_model(r\"complexSphere.ply\")\n",
    "pencil = load_cad_model(r\"pencil_fein.ply\")\n",
    "# source: https://sketchfab.com/3d-models/davis-teapot-materialcleanup-547971eaf21d43f2b6cfcb6be0e7bf11\n",
    "teapot = load_cad_model(r\"teapot.ply\")\n",
    "# source: https://sketchfab.com/3d-models/book-ba04f5ac66194341bc7d437fb6c94674\n",
    "book = load_cad_model(r\"book.ply\")"
   ],
   "id": "fb44a471c057b4a8",
   "outputs": [],
   "execution_count": 182
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "ICP Algorithmus Implementierung",
   "id": "5eaacbe1d4b97d5f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T15:46:38.330189Z",
     "start_time": "2024-06-14T15:46:38.313672Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def icp_algorithm(source, target):\n",
    "    # transform target point cloud\n",
    "    transformation = np.array([[0.86, 0.5, 0.1, 0.5],\n",
    "                               [-0.5, 0.86, 0.1, 0.99],\n",
    "                               [0.0, -0.1, 0.99, 0.5],\n",
    "                               [1.3, 0.0, 0.0, 1.0]])\n",
    "    target = target.transform(transformation)\n",
    "    \n",
    "    threshold = 0.25  # max distance for deleting points\n",
    "    initial_transformation = np.identity(4)  # initial guess of transformation\n",
    "    \n",
    "    # Open3D ICP Algorithmus\n",
    "    reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "        source, target, threshold, initial_transformation,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint())\n",
    "    source.transform(reg_p2p.transformation)\n",
    "    return reg_p2p\n"
   ],
   "id": "acbc5ea2a52a8d36",
   "outputs": [],
   "execution_count": 183
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ergebnisse in CSV schreiben",
   "id": "f86a8f451739a5c5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T15:46:38.358515Z",
     "start_time": "2024-06-14T15:46:38.332680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import csv\n",
    "\n",
    "def write_csv(array, filename):\n",
    "\n",
    "    # Öffne die CSV-Datei im Schreibmodus\n",
    "    with open(filename, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        for row in array:\n",
    "            writer.writerow([row])"
   ],
   "id": "201d284b520fce40",
   "outputs": [],
   "execution_count": 184
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Test Reproduzierbarkeit",
   "id": "ae2d3719e061ce9d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T15:46:38.373703Z",
     "start_time": "2024-06-14T15:46:38.360863Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "\n",
    "#Test für Stabilität der Ergebnisse\n",
    "# Konfiguration des Loggings\n",
    "log_filename = 'downsampling.log'\n",
    "#if os.path.exists(log_filename):\n",
    "  #  os.remove(log_filename)\n",
    "    \n",
    "logging.basicConfig(\n",
    "    filename=log_filename,\n",
    "    filemode='w',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "num_iterations = 25\n",
    "output_dir_pc = 'point_cloud_images'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "model_array = [cube, sphere, cone, complex_cone, complex_cube, complex_sphere, pencil, teapot, book]"
   ],
   "id": "1387db1d751ac27f",
   "outputs": [],
   "execution_count": 185
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Visualisierung\n",
    "rd_chamfer_distances = [\n",
    "    [  # Modell 1\n",
    "        [ch_dist_1_2, ch_dist_1_3, ch_dist_1_4],  # Iteration 1 (zu Iteration 2, 3, 4)\n",
    "        [ch_dist_2_3, ch_dist_2_4],               # Iteration 2 (zu Iteration 3, 4)\n",
    "        [ch_dist_3_4]                             # Iteration 3 (zu Iteration 4)\n",
    "    ],\n",
    "    [  # Modell 2\n",
    "        [ch_dist_1_2, ch_dist_1_3, ch_dist_1_4],\n",
    "        [ch_dist_2_3, ch_dist_2_4],\n",
    "        [ch_dist_3_4]\n",
    "    ],\n",
    "    [  # Modell 3\n",
    "        [ch_dist_1_2, ch_dist_1_3, ch_dist_1_4],\n",
    "        [ch_dist_2_3, ch_dist_2_4],\n",
    "        [ch_dist_3_4]\n",
    "    ]\n",
    "]\n"
   ],
   "id": "75a23c127e3b319f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Wasserstein-Distanz",
   "id": "ddee6cb148f8d9bf"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "rd_wasserstein = []\n",
    "vf_wasserstein = []\n",
    "fp_wasserstein = []\n",
    "\n",
    "seed_value = 42\n",
    "\n",
    "for model in model_array:\n",
    "    for i in range(num_iterations):\n",
    "\n",
    "        # Punktewolke zufällig verrauschen\n",
    "        random.seed(seed_value)\n",
    "        random_number = random.random()\n",
    "        \n",
    "        model = add_noise(model, random_number)\n",
    "        \n",
    "        #random downsampling\n",
    "        rd = random_downsampling(model, int(len(model.points)/10 * 4))\n",
    "                \n",
    "        # voxelgrid\n",
    "        vx_grid = create_voxel_grid(model, 0.2)\n",
    "        vx = voxel_filter(model, vx_grid, 0.2)\n",
    "\n",
    "        # farthest point downsampling\n",
    "        fp= farthest_point_sampling(model,int(len(model.points)/10 * 4))\n",
    "\n",
    "        # Random Downsampling\n",
    "        rd_wasserstein.append(gromov_wasserstein(rd,model))\n",
    "        # Voxelgrid Filter\n",
    "        vf_wasserstein.append(gromov_wasserstein(vx,model))\n",
    "        # Farthest Point Downsampling\n",
    "        fp_wasserstein.append(gromov_wasserstein(fp,model))\n",
    "                    \n",
    "write_csv(rd_wasserstein,\"rd_wasserstein.csv\")\n",
    "write_csv(vf_wasserstein,\"vf_wasserstein.csv\")\n",
    "write_csv(fp_wasserstein,\"fp_wasserstein.csv\")\n",
    "\n",
    "print(rd_wasserstein)\n",
    "print(vf_wasserstein)\n",
    "print(fp_wasserstein)\n"
   ],
   "id": "e1e79bee971ab363",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Laufzeittest",
   "id": "e0f9402fc2f869a6"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "rd_times = []  # List of lists for random downsampling times\n",
    "vf_times = []  # List of lists for voxel filter times\n",
    "fp_times = []  # List of lists for farthest point sampling times\n",
    "\n",
    "# Methode Spalte, Modell Zeile ?\n",
    "# [][][]    \n",
    "# [][][]\n",
    "\n",
    "for i, model in enumerate(model_array):\n",
    "    for round in range(num_iterations):\n",
    "        \n",
    "        # random downsampling\n",
    "        start = time.time()\n",
    "        rd = random_downsampling(model, int(len(model.points)/10 * 4))\n",
    "        end = time.time()\n",
    "        elapsed_time = end - start\n",
    "        rd_times.append(elapsed_time)    \n",
    "            \n",
    "        # voxelgrid filter\n",
    "        start = time.time()\n",
    "        vx_grid = create_voxel_grid(model, 0.2)\n",
    "        vx = voxel_filter(model, vx_grid, 0.7)\n",
    "        end = time.time()\n",
    "        elapsed_time = end - start\n",
    "        vf_times.append(elapsed_time)\n",
    "            \n",
    "        # farthest point downsampling\n",
    "        start = time.time()\n",
    "        fp= farthest_point_sampling(model,int(len(model.points)/10 * 4))\n",
    "        end = time.time()\n",
    "        fp_pc = o3d.geometry.PointCloud()\n",
    "        fp_pc.points = o3d.utility.Vector3dVector(np.asarray(fp.points))\n",
    "        elapsed_time = end - start\n",
    "        fp_times.append(elapsed_time)  # Add the time to the corresponding model's list\n",
    "        \n",
    "write_csv(rd_times,\"rd_times.csv\")\n",
    "write_csv(vf_times,\"vf_times.csv\")\n",
    "write_csv(fp_times,\"fp_times.csv\")"
   ],
   "id": "30bb7091f0189d22",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "ICP Tests",
   "id": "df7ee548165a3048"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Vergleich auf den Originalwolken\n",
    "original_fitness = []  \n",
    "original_inlier = [] \n",
    "\n",
    "model_array = [cube]\n",
    "for model in model_array:\n",
    "    for round in range(num_iterations):\n",
    "        \n",
    "             # ICP auf den Originalpunktewolken\n",
    "            rd_icp = icp_algorithm(add_noise(model, 0.7), model)\n",
    "            original_fitness.append(rd_icp.fitness)  \n",
    "            original_inlier.append(rd_icp.inlier_rmse)    \n",
    "\n",
    "write_csv(original_fitness,\"original_fitness.csv\")\n",
    "write_csv(original_fitness,\"original_icp_fitness.csv\")"
   ],
   "id": "affd0a77242da4cc"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "rd_icp_fitness = []  \n",
    "rd_icp_inlier = []  \n",
    "vf_icp_fitness = [] \n",
    "vf_icp_inlier = []  \n",
    "fp_icp_fitness = [] \n",
    "fp_icp_inlier = []  \n",
    "\n",
    "model_array = [cube]\n",
    "for model in model_array:\n",
    "    for round in range(num_iterations):\n",
    "        \n",
    "             # random downsampling\n",
    "            model_rd= random_downsampling(model, int(len(model.points)/10 * 4))\n",
    "            model_rd_pc = o3d.geometry.PointCloud()\n",
    "            model_rd_pc.points = o3d.utility.Vector3dVector(np.asarray(model_rd.points))\n",
    "            rd_icp = icp_algorithm(model_rd_pc, model)\n",
    "            rd_icp_fitness.append(rd_icp.fitness)  \n",
    "            rd_icp_inlier.append(rd_icp.inlier_rmse)    \n",
    "\n",
    "            # voxel grid filter\n",
    "            model_voxel_grid = create_voxel_grid(model, 0.2)\n",
    "            model_voxel = voxel_filter(model, model_voxel_grid,0.2)\n",
    "            vf_icp = icp_algorithm(model_voxel,model)\n",
    "            vf_icp_fitness.append(vf_icp.fitness)    \n",
    "            vf_icp_inlier.append(rd_icp.inlier_rmse)    \n",
    "\n",
    "            # farthest point downsampling#\n",
    "            model_fp = farthest_point_sampling(model,int(len(model.points)/10 * 4))\n",
    "            model_fp_pc = o3d.geometry.PointCloud()\n",
    "            model_fp_pc.points = o3d.utility.Vector3dVector(np.asarray(model_fp.points))\n",
    "            fp_icp = icp_algorithm(model_fp_pc,model)\n",
    "            fp_icp_fitness.append(fp_icp.fitness) \n",
    "            fp_icp_inlier.append(fp_icp.inlier_rmse)    \n",
    "\n",
    "\n",
    "write_csv(rd_icp_fitness,\"rd_icp_fitness.csv\")\n",
    "write_csv(vf_icp_fitness,\"vf_icp_fitness.csv\")\n",
    "write_csv(fp_icp_fitness,\"fp_icp_fitness.csv\")\n",
    "write_csv(rd_icp_inlier,\"rd_icp_inlier.csv\")\n",
    "write_csv(vf_icp_inlier,\"vf_icp_inlier.csv\")\n",
    "write_csv(fp_icp_inlier,\"fp_icp_inlier.csv\")"
   ],
   "id": "f2ae2791168b938f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Noisiness test basic models",
   "id": "b3915e0c231b90ca"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "model_array = [cube]#,cube,cone]\n",
    "model_names = [\"sphere\",\"cube\",\"cone\"]\n",
    "for index, model in enumerate(model_array):\n",
    "    # create noisy pointclouds\n",
    "    noisy_model= add_noise(model,1.3)\n",
    "    \n",
    "    # Random Downsampling\n",
    "    rd_noisy = random_downsampling(noisy_model,int(len(noisy_model.points)/10 * 4))\n",
    "    point_cloud_to_ply(rd_noisy, \"noisy_rd_\"+model_names[index])\n",
    "\n",
    "    # Voxel Grid Filter\n",
    "    noisy_model_grid = create_voxel_grid(noisy_model, 0.2)\n",
    "    noisy_model_voxel_pc= voxel_filter(noisy_model, noisy_model_grid,0.2)\n",
    "    point_cloud_to_ply(noisy_model_voxel_pc, \"noisy_vf_\"+model_names[index])\n",
    "    \n",
    "    # Farthest Point Downsampling\n",
    "    noisy_model_fp = farthest_point_sampling(noisy_model,int(len(noisy_model.points)/10 * 4))\n",
    "    noisy_model_fp_pc = o3d.geometry.PointCloud()\n",
    "    noisy_model_fp_pc.points = o3d.utility.Vector3dVector(np.asarray(noisy_model_fp.points))\n",
    "    point_cloud_to_ply(noisy_model_fp_pc, \"noisy_fp_\"+model_names[index])\n"
   ],
   "id": "8d66fc758daa7984",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "noisiness tests complex models",
   "id": "4614eecfb0cb5f76"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "model_array = [complex_sphere,complex_cube,complex_cone]\n",
    "model_names = [\"complex_sphere\",\"complex_cube\",\"complex_cone\"]\n",
    "\n",
    "for index, complex_model in enumerate(model_array):\n",
    "\n",
    "    noisy_complex_model =add_noise(complex_model,1.3)\n",
    "    rd_complex_noisy = random_downsampling(noisy_complex_model,int(len(noisy_complex_model.points)/10 * 4))\n",
    "    point_cloud_to_ply(rd_complex_noisy, \"noisy_rd_\"+model_names[index])\n",
    "\n",
    "    noisy_complex_model_grid = create_voxel_grid(noisy_complex_model, 0.2)\n",
    "    noisy_complex_model_voxel_pc = voxel_filter(noisy_complex_model, noisy_complex_model_grid,0.2)\n",
    "    point_cloud_to_ply(noisy_complex_model_voxel_pc, \"noisy_vf_\"+model_names[index])\n",
    "\n",
    "    noisy_complex_model_fp = farthest_point_sampling(noisy_complex_model,int(len(noisy_complex_model.points)/10 * 4))\n",
    "    noisy_complex_model_fp_pc = o3d.geometry.PointCloud()\n",
    "    noisy_complex_model_fp_pc.points = o3d.utility.Vector3dVector(np.asarray(noisy_complex_model_fp.points))\n",
    "    point_cloud_to_ply(noisy_complex_model_fp_pc, \"noisy_fp_\"+model_names[index])"
   ],
   "id": "c8bbfb52eaf0dd2d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "noisiness tests objects",
   "id": "8a7a286ea5d1bbce"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "model_array = [teapot] #,book,pencil]\n",
    "model_names = [\"teapot\",\"book\",\"pencil\"]\n",
    "\n",
    "for index, model_object in enumerate(model_array):\n",
    "        \n",
    "    # random downsampling\n",
    "    noisy_model_object = add_noise(model_object,0.1)\n",
    "    rd_noisy = random_downsampling(noisy_model_object, int(len(noisy_model_object.points)/10 * 4))\n",
    "    point_cloud_to_ply(rd_noisy, \"noisy_rd_\"+model_names[index]+\".ply\")\n",
    "\n",
    "    # voxel grid filter\n",
    "    noisy_model_object_grid = create_voxel_grid(noisy_model_object, 0.2)\n",
    "    noisy_object_voxel_pc = voxel_filter(noisy_model_object, noisy_model_object_grid,0.2)\n",
    "    point_cloud_to_ply(noisy_object_voxel_pc, \"noisy_vf_\"+model_names[index]+\".ply\")\n",
    "\n",
    "    # farthest point downsampling\n",
    "    noisy_model_object_fp = farthest_point_sampling(noisy_model_object,int(len(noisy_model_object.points)/10 * 4))\n",
    "    noisy_model_object_fp_pc = o3d.geometry.PointCloud()\n",
    "    noisy_model_object_fp_pc.points = o3d.utility.Vector3dVector(np.asarray(noisy_model_object_fp.points))\n",
    "    point_cloud_to_ply(noisy_model_object_fp_pc, \"noisy_fp_\"+model_names[index]+\".ply\")"
   ],
   "id": "979984132ccf6e65",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "a13a509dd712e465"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
