{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-22T07:19:25.975689Z",
     "start_time": "2024-06-22T07:19:24.175454Z"
    }
   },
   "source": [
    "#Imports\n",
    "from io import BytesIO\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "import open3d as o3d\n",
    "import random\n",
    "import requests\n",
    "import tarfile\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "from scipy.spatial.distance import pdist, squareform"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T07:19:26.952930Z",
     "start_time": "2024-06-22T07:19:26.938326Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def gromov_wasserstein(pc1: np.ndarray, pc2: np.ndarray) -> float:\n",
    "    def dist_ecc_fast(ecc, u):\n",
    "        return (np.mean(ecc <= u))\n",
    "\n",
    "    out = 0\n",
    "    # Konvertiere die Punktwolken in NumPy-Arrays\n",
    "    pc1 = np.asarray(pc1.points)\n",
    "    pc2 = np.asarray(pc2.points)\n",
    "\n",
    "    # Reshape input matrices if necessary\n",
    "    if pc1.ndim == 1:\n",
    "        pc1 = pc1.reshape(-1, 1)\n",
    "    if pc2.ndim == 1:\n",
    "        pc2 = pc2.reshape(-1, 1)\n",
    "\n",
    "    ecc1 = squareform(pdist(pc1)).mean(0)\n",
    "    ecc2 = squareform(pdist(pc2)).mean(0)\n",
    "    unique_ecc = np.unique(np.concatenate((ecc1, ecc2)))\n",
    "    for i in range(unique_ecc.shape[0] - 1):\n",
    "        u = unique_ecc[i]\n",
    "        out += (unique_ecc[i + 1] - unique_ecc[i]) * np.abs(dist_ecc_fast(ecc1, u) - dist_ecc_fast(ecc2, u))\n",
    "\n",
    "    return (0.5 * out)"
   ],
   "id": "7e1568af12c11b07",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T07:19:27.581155Z",
     "start_time": "2024-06-22T07:19:27.574920Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_pcd_from_mesh(mesh):\n",
    "    mesh.compute_vertex_normals()\n",
    "    o3d.visualization.draw_geometries([mesh])\n",
    "    # distribute dots evenly on the surface\n",
    "    return mesh.sample_points_uniformly(500)"
   ],
   "id": "77f3497eebb98499",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T07:19:27.890496Z",
     "start_time": "2024-06-22T07:19:27.871524Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_model(link, path):\n",
    "    # http://ycb-benchmarks.s3-website-us-east-1.amazonaws.com/\n",
    "    response = requests.get(link)\n",
    "    tgz_data = BytesIO(response.content)\n",
    "    # set the current working directory to the script's directory\n",
    "    script_directory = os.path.dirname(os.path.abspath(__file__))\n",
    "    os.chdir(script_directory)\n",
    "    with tarfile.open(fileobj=tgz_data, mode=\"r:gz\") as tar_ref:\n",
    "        tar_ref.extractall(script_directory)\n",
    "    # join paths\n",
    "    model_path = os.path.join(script_directory, path, \"clouds\", \"merged_cloud.ply\")\n",
    "    # load pointcloud\n",
    "    pcd = o3d.io.read_point_cloud(model_path)\n",
    "    return pcd"
   ],
   "id": "7a14771974f89559",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T07:19:28.185190Z",
     "start_time": "2024-06-22T07:19:28.168176Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_cad_model(model):\n",
    "    # load model generated in freecad\n",
    "    return o3d.io.read_point_cloud(model)"
   ],
   "id": "268acea18c088fe8",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T07:19:28.600866Z",
     "start_time": "2024-06-22T07:19:28.589610Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def visualize_model(model):\n",
    "    o3d.visualization.draw_geometries([model])"
   ],
   "id": "a6cb10deb5b2cada",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T07:19:28.864156Z",
     "start_time": "2024-06-22T07:19:28.853333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_num_points(model):\n",
    "    print(len(model.points))"
   ],
   "id": "b24f412aa7c9f798",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T07:19:29.035657Z",
     "start_time": "2024-06-22T07:19:29.020634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_pointcloud_from_coordinates(coordinates):\n",
    "    # create point cloud with coordinates\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(coordinates)\n",
    "    return pcd"
   ],
   "id": "9d07c2e658e06523",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T07:19:29.365420Z",
     "start_time": "2024-06-22T07:19:29.347787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_coordinates(model):\n",
    "    coordinates = [list(point) for point in model.points]\n",
    "    # print(coordinates[:50])\n",
    "    return coordinates"
   ],
   "id": "dcdc0ec299624eba",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T07:19:29.735135Z",
     "start_time": "2024-06-22T07:19:29.716210Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def random_downsampling(model, endpoints):\n",
    "    # get coordinates of the models\n",
    "    coordinates = get_coordinates(model)\n",
    "    # select random points for downsampling\n",
    "    for i in range(len(coordinates) - endpoints):\n",
    "        rannumb = random.randint(0, len(coordinates) - 1)\n",
    "        del coordinates[rannumb]\n",
    "    point_cloud = create_pointcloud_from_coordinates(coordinates)\n",
    "    return point_cloud"
   ],
   "id": "2052f3d3ed6ad35a",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T07:19:30.298122Z",
     "start_time": "2024-06-22T07:19:30.284826Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def farthest_point_sampling(model, num_points_keep):\n",
    "    coordinates = np.array(get_coordinates(model))\n",
    "    retVal = []\n",
    "    # to make runs comparable\n",
    "    random.seed(13)\n",
    "    # generate \"random\" int\n",
    "    randint = random.randint(0, len(coordinates) - 1)\n",
    "    # select random point from model\n",
    "    retVal.append(coordinates[randint])\n",
    "    # delete chosen point from original model after it was added to the downsampled cloud\n",
    "    coordinates = np.delete(coordinates, randint, axis=0)\n",
    "    while len(retVal) < num_points_keep:\n",
    "        # Berechne die euklidischen Distanzen der ausgewählten Punkte zu den verbleibenden Punkten\n",
    "        eucl_distances = distance.cdist(retVal, coordinates, 'euclidean')\n",
    "        # Find point with largest min Distance\n",
    "        min_mindist = np.min(eucl_distances, axis=0)\n",
    "        # Find index of point with largest min DIstance\n",
    "        max_min_distance_index = np.argmax(min_mindist)\n",
    "        # add point that is farthest away\n",
    "        retVal.append(coordinates[max_min_distance_index])\n",
    "        # delete point from coordinates list \n",
    "        coordinates = np.delete(coordinates, max_min_distance_index, axis=0)\n",
    "    return create_pointcloud_from_coordinates(np.array(retVal))"
   ],
   "id": "c93a96564378e9f4",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T07:19:31.034549Z",
     "start_time": "2024-06-22T07:19:31.022667Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# built in function von open3d\n",
    "def radius_outlier_removal_call(model):\n",
    "    return model.remove_radius_outlier(nb_points=5, radius=0.05)"
   ],
   "id": "42dd39bb15f7e3e1",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T07:19:31.533802Z",
     "start_time": "2024-06-22T07:19:31.522780Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# add noise to pointcloud\n",
    "def add_noise(model, noise_value):\n",
    "    points = np.asarray(model.points)\n",
    "    noise = np.random.normal(0, noise_value, size=points.shape)\n",
    "    noisy_points = points + noise\n",
    "\n",
    "    noisy_pc = o3d.geometry.PointCloud()\n",
    "    noisy_pc.points = o3d.utility.Vector3dVector(noisy_points)\n",
    "    return noisy_pc"
   ],
   "id": "4b8175616d52ffb4",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T07:19:32.256123Z",
     "start_time": "2024-06-22T07:19:32.232390Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_voxel_grid(model, voxel_size):\n",
    "    model_points = np.array(get_coordinates(model))\n",
    "    min_bound = np.min(model_points, axis=0)\n",
    "    max_bound = np.max(model_points, axis=0)\n",
    "\n",
    "    dimensions = np.ceil((max_bound - min_bound) / voxel_size).astype(int)\n",
    "\n",
    "    voxelgrid = np.zeros(dimensions)\n",
    "\n",
    "    for point in model_points:\n",
    "        voxel_coordinates = ((point - min_bound) / voxel_size).astype(int)\n",
    "        # -1 needed in order to avoid index out of bounds\n",
    "        voxelgrid[tuple(voxel_coordinates - 1)] += 1\n",
    "    # convert voxelgrid to open3d Voxelgrid\n",
    "    o3d_voxelgrid = o3d.geometry.VoxelGrid.create_from_point_cloud(input=model, voxel_size=voxel_size)\n",
    "    #o3d.visualization.draw_geometries([o3d_voxelgrid])\n",
    "    return o3d_voxelgrid\n",
    "\n",
    "\n",
    "def voxel_filter(model, voxelgrid, voxel_size):\n",
    "    # list where downsampled points will be saved\n",
    "    downsampled_points = []\n",
    "    # iterate over all voxel in the voxelgrid\n",
    "    for voxel in voxelgrid.get_voxels():\n",
    "        # get bounds of the voxel\n",
    "        downsampled_points.extend(is_point_in_voxel(model, voxelgrid, voxel, voxel_size))\n",
    "    downsampled_points = np.asarray(downsampled_points)\n",
    "    return create_pointcloud_from_coordinates(downsampled_points)\n",
    "\n",
    "\n",
    "def aggregate_points(points):\n",
    "    # Aggregate the points by averaging, taking into account the z coordinate\n",
    "    if len(points) == 0:\n",
    "        return points\n",
    "    aggregated_points = []\n",
    "    aggregated_points.append(np.mean(points, axis=0))\n",
    "    return aggregated_points\n",
    "\n",
    "\n",
    "def is_point_in_voxel(model, voxelgrid, voxel, voxel_size):\n",
    "    # get center point and see whether a point lies within the given distance/2 of the voxel size from the center\n",
    "    voxel_center = voxelgrid.get_voxel_center_coordinate(voxel.grid_index)\n",
    "    points_in_voxel = []\n",
    "    half_size = voxel_size / 2.0\n",
    "    # check, which points are lying within a voxel\n",
    "    for point in model.points:\n",
    "        if np.all(np.abs(point - voxel_center) <= half_size):\n",
    "            points_in_voxel.append(point)\n",
    "    points_in_voxel = aggregate_points(points_in_voxel)\n",
    "    # print(points_in_voxel)\n",
    "    return points_in_voxel\n",
    "\n",
    "\n",
    "def create_points_from_voxel(voxel_model):\n",
    "    # convert vector in numpy array\n",
    "    vector_array = np.asarray(voxel_model)\n",
    "\n",
    "    # create o3d point cloud\n",
    "    point_cloud = o3d.geometry.PointCloud()\n",
    "    point_cloud.points = o3d.utility.Vector3dVector(vector_array)\n",
    "\n",
    "    return point_cloud\n"
   ],
   "id": "d80e628c3ec6ce94",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T07:19:35.039116Z",
     "start_time": "2024-06-22T07:19:35.025916Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def point_cloud_to_ply(point_cloud, file_name):\n",
    "    # safe downsampled point cloud as ply data\n",
    "    file_name = \"point_cloud_images/\" + file_name + \".ply\"\n",
    "    if os.path.exists(\"point_cloud_images/\" + file_name):\n",
    "        os.remove(file_name)\n",
    "    o3d.io.write_point_cloud(file_name, o3d.geometry.PointCloud(point_cloud.points))"
   ],
   "id": "efa529414d46c342",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T18:23:31.449151Z",
     "start_time": "2024-06-22T18:23:31.381636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def point_cloud_to_ply_simple(point_cloud, file_name):\n",
    "    # safe downsampled point cloud as ply data\n",
    "    file_name = \"point_cloud_images_simple/\" + file_name + \".ply\"\n",
    "    if os.path.exists(\"point_cloud_images_simple/\" + file_name):\n",
    "        os.remove(file_name)\n",
    "    o3d.io.write_point_cloud(file_name, o3d.geometry.PointCloud(point_cloud.points))"
   ],
   "id": "7a956b9b81e90349",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Laden der Punktewolken",
   "id": "db51eef7e9ea26fd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T18:23:33.814176Z",
     "start_time": "2024-06-22T18:23:33.526535Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cone = load_cad_model(r\"cone.ply\")\n",
    "sphere = load_cad_model(r\"sphere.ply\")\n",
    "cube = load_cad_model(r\"cube.ply\")\n",
    "complex_cube = load_cad_model(r\"complexCube.ply\")\n",
    "complex_cone = load_cad_model(r\"hollowCone.ply\")\n",
    "complex_sphere = load_cad_model(r\"complexSphere.ply\")\n",
    "pencil = load_cad_model(r\"pencil_fein.ply\")\n",
    "# source: https://sketchfab.com/3d-models/davis-teapot-materialcleanup-547971eaf21d43f2b6cfcb6be0e7bf11\n",
    "teapot = load_cad_model(r\"teapot.ply\")\n",
    "# source: https://sketchfab.com/3d-models/book-ba04f5ac66194341bc7d437fb6c94674\n",
    "book = load_cad_model(r\"book.ply\")"
   ],
   "id": "fb44a471c057b4a8",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "ICP Algorithmus Implementierung",
   "id": "5eaacbe1d4b97d5f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T07:19:38.082759Z",
     "start_time": "2024-06-22T07:19:38.069768Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def icp_algorithm(source, target):\n",
    "    # transform target point cloud\n",
    "    transformation = np.array([[0.86, 0.5, 0.1, 0.5],\n",
    "                               [-0.5, 0.86, 0.1, 0.99],\n",
    "                               [0.0, -0.1, 0.99, 0.5],\n",
    "                               [1.3, 0.0, 0.0, 1.0]])\n",
    "    target = target.transform(transformation)\n",
    "\n",
    "    threshold = 0.25  # max distance for deleting points\n",
    "    initial_transformation = np.identity(4)  # initial guess of transformation\n",
    "\n",
    "    # Open3D ICP Algorithmus\n",
    "    reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "        source, target, threshold, initial_transformation,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint())\n",
    "    source.transform(reg_p2p.transformation)\n",
    "    return reg_p2p\n"
   ],
   "id": "acbc5ea2a52a8d36",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ergebnisse in CSV schreiben",
   "id": "f86a8f451739a5c5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T07:19:39.561889Z",
     "start_time": "2024-06-22T07:19:39.548985Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def write_csv(array, filename):\n",
    "    # Öffne die CSV-Datei im Schreibmodus\n",
    "    with open(filename, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        for row in array:\n",
    "            writer.writerow([row])"
   ],
   "id": "201d284b520fce40",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Test Reproduzierbarkeit Rauschen und Gromov-Wasserstein Distanz",
   "id": "ae2d3719e061ce9d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T11:32:52.197777Z",
     "start_time": "2024-06-20T09:52:27.981884Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rd_wasserstein = []\n",
    "vf_wasserstein = []\n",
    "fp_wasserstein = []\n",
    "\n",
    "num_iterations = 10\n",
    "model_array = [cube, sphere, cone, complex_cube, complex_cone, complex_sphere,\n",
    "               pencil, teapot, book]\n",
    "array_noise = [0.05, 0.2, 1]\n",
    "for model in model_array:\n",
    "    for noise in array_noise:\n",
    "        for i in range(num_iterations):\n",
    "            model = add_noise(model, noise)\n",
    "\n",
    "            #random downsampling\n",
    "            rd = random_downsampling(model, int(len(model.points) / 10 * 4))\n",
    "\n",
    "            # voxelgrid\n",
    "            vx_grid = create_voxel_grid(model, 0.2)\n",
    "            vx = voxel_filter(model, vx_grid, 0.2)\n",
    "\n",
    "            # farthest point downsampling\n",
    "            fp = farthest_point_sampling(model, int(len(model.points) / 10 * 4))\n",
    "\n",
    "            # Random Downsampling\n",
    "            rd_wasserstein.append(gromov_wasserstein(rd, model))\n",
    "            # Voxelgrid Filter\n",
    "            vf_wasserstein.append(gromov_wasserstein(vx, model))\n",
    "            # Farthest Point Downsampling\n",
    "            fp_wasserstein.append(gromov_wasserstein(fp, model))\n",
    "\n",
    "            print(i)\n",
    "\n",
    "write_csv(rd_wasserstein, \"rd_wasserstein.csv\")\n",
    "write_csv(vf_wasserstein, \"vf_wasserstein.csv\")\n",
    "write_csv(fp_wasserstein, \"fp_wasserstein.csv\")\n",
    "\n",
    "print(rd_wasserstein)\n",
    "print(vf_wasserstein)\n",
    "print(fp_wasserstein)\n"
   ],
   "id": "e1e79bee971ab363",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "[0.2705866962525741, 0.09077863392603658, 0.09040394193458741, 0.09012493471875607, 0.09032806159254894, 0.09064595901392264, 0.09081015707767472, 0.09051769128054409, 0.09087100194533458, 0.09100855293880897, 0.0922270810223527, 0.09380357259387846, 0.09431286800254036, 0.09222332103671005, 0.09200205698689473, 0.09305364286790276, 0.09251122263758596, 0.09241460383976288, 0.09133464761685794, 0.09126492511066028, 0.09709291277717733, 0.10131523865305526, 0.11661935309986046, 0.12100764792659603, 0.11350478590567419, 0.11304301416130512, 0.11193416216748583, 0.11047181206616286, 0.10708674512802444, 0.1118358187180887]\n",
      "[5.427020676873916, 5.380804378791626, 5.313625265971279, 5.313716712643975, 5.185630644699037, 5.150867098484675, 5.068467151002501, 5.0530188164980006, 5.018578927648757, 4.934578556195397, 4.431708587827005, 4.0243785225533175, 3.6768758663047802, 3.385778716078735, 3.058387405848977, 2.80009206396991, 2.618203519934875, 2.3931745705221057, 2.2454185728055926, 2.0983466728254045, 0.6209216924309475, 0.3535481648429584, 0.1999622122093585, 0.15014320989310376, 0.10383583565177842, 0.09106672519463267, 0.07931363486179116, 0.06336485902402897, 0.05313326302929689, 0.059929603821885544]\n",
      "[6.217174431030691, 6.276125704909142, 6.303510295382989, 6.309374231854885, 6.3382631504508415, 6.354910421393487, 6.377586486379269, 6.386224815094574, 6.394788003141216, 6.396433269774092, 6.437916610428692, 6.488335342355508, 6.523835741561613, 6.560901838090065, 6.558417977852874, 6.563833674106713, 6.572971161296956, 6.597883712221651, 6.613228449136452, 6.621884489230054, 6.639423873671042, 6.708269979425678, 6.658113512070726, 6.687705779998461, 6.6114177090398805, 6.65606049537208, 6.712538377296238, 6.662146109845106, 6.7032918744320344, 6.5731617904265915]\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#Results\n",
    "[0.2705866962525741, 0.09077863392603658, 0.09040394193458741, 0.09012493471875607, 0.09032806159254894, 0.09064595901392264, 0.09081015707767472, 0.09051769128054409, 0.09087100194533458, 0.09100855293880897, 0.0922270810223527, 0.09380357259387846, 0.09431286800254036, 0.09222332103671005, 0.09200205698689473, 0.09305364286790276, 0.09251122263758596, 0.09241460383976288, 0.09133464761685794, 0.09126492511066028, 0.09709291277717733, 0.10131523865305526, 0.11661935309986046, 0.12100764792659603, 0.11350478590567419, 0.11304301416130512, 0.11193416216748583, 0.11047181206616286, 0.10708674512802444, 0.1118358187180887]\n",
    "[5.427020676873916, 5.380804378791626, 5.313625265971279, 5.313716712643975, 5.185630644699037, 5.150867098484675, 5.068467151002501, 5.0530188164980006, 5.018578927648757, 4.934578556195397, 4.431708587827005, 4.0243785225533175, 3.6768758663047802, 3.385778716078735, 3.058387405848977, 2.80009206396991, 2.618203519934875, 2.3931745705221057, 2.2454185728055926, 2.0983466728254045, 0.6209216924309475, 0.3535481648429584, 0.1999622122093585, 0.15014320989310376, 0.10383583565177842, 0.09106672519463267, 0.07931363486179116, 0.06336485902402897, 0.05313326302929689, 0.059929603821885544]\n",
    "[6.217174431030691, 6.276125704909142, 6.303510295382989, 6.309374231854885, 6.3382631504508415, 6.354910421393487, 6.377586486379269, 6.386224815094574, 6.394788003141216, 6.396433269774092, 6.437916610428692, 6.488335342355508, 6.523835741561613, 6.560901838090065, 6.558417977852874, 6.563833674106713, 6.572971161296956, 6.597883712221651, 6.613228449136452, 6.621884489230054, 6.639423873671042, 6.708269979425678, 6.658113512070726, 6.687705779998461, 6.6114177090398805, 6.65606049537208, 6.712538377296238, 6.662146109845106, 6.7032918744320344, 6.5731617904265915]"
   ],
   "id": "f3ba021b1a2b64bd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Laufzeittest",
   "id": "e0f9402fc2f869a6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rd_times = []  # List of lists for random downsampling times\n",
    "vf_times = []  # List of lists for voxel filter times\n",
    "fp_times = []  # List of lists for farthest point sampling times\n",
    "\n",
    "# Methode Spalte, Modell Zeile ?\n",
    "# [][][]    \n",
    "# [][][]\n",
    "model_array = [cube, sphere, cone, complex_cube, complex_cone, complex_sphere,\n",
    "               pencil, teapot, book]\n",
    "for i, model in enumerate(model_array):\n",
    "    for round in range(num_iterations):\n",
    "        # random downsampling\n",
    "        start = time.time()\n",
    "        rd = random_downsampling(model, int(len(model.points) / 10 * 4))\n",
    "        end = time.time()\n",
    "        elapsed_time = end - start\n",
    "        rd_times.append(elapsed_time)\n",
    "\n",
    "        # voxelgrid filter\n",
    "        start = time.time()\n",
    "        vx_grid = create_voxel_grid(model, 0.2)\n",
    "        vx = voxel_filter(model, vx_grid, 0.7)\n",
    "        end = time.time()\n",
    "        elapsed_time = end - start\n",
    "        vf_times.append(elapsed_time)\n",
    "\n",
    "        # farthest point downsampling\n",
    "        start = time.time()\n",
    "        fp = farthest_point_sampling(model, int(len(model.points) / 10 * 4))\n",
    "        end = time.time()\n",
    "        fp_pc = o3d.geometry.PointCloud()\n",
    "        fp_pc.points = o3d.utility.Vector3dVector(np.asarray(fp.points))\n",
    "        elapsed_time = end - start\n",
    "        fp_times.append(elapsed_time)  # Add the time to the corresponding model's list\n",
    "\n",
    "write_csv(rd_times, \"rd_times.csv\")\n",
    "write_csv(vf_times, \"vf_times.csv\")\n",
    "write_csv(fp_times, \"fp_times.csv\")"
   ],
   "id": "30bb7091f0189d22",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "ICP Tests",
   "id": "df7ee548165a3048"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Vergleich auf den Originalwolken\n",
    "original_fitness = []\n",
    "original_inlier = []\n",
    "\n",
    "for model in model_array:\n",
    "    # ICP auf den Originalpunktewolken\n",
    "    rd_icp = icp_algorithm(add_noise(model, 0.7), model)\n",
    "    original_fitness.append(rd_icp.fitness)\n",
    "    original_inlier.append(rd_icp.inlier_rmse)\n",
    "\n",
    "write_csv(original_fitness, \"original_fitness.csv\")\n",
    "write_csv(original_fitness, \"original_icp_fitness.csv\")"
   ],
   "id": "affd0a77242da4cc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rd_icp_fitness = []\n",
    "rd_icp_inlier = []\n",
    "vf_icp_fitness = []\n",
    "vf_icp_inlier = []\n",
    "fp_icp_fitness = []\n",
    "fp_icp_inlier = []\n",
    "\n",
    "for model in model_array:\n",
    "    # random downsampling\n",
    "    model_rd = random_downsampling(model, int(len(model.points) / 10 * 4))\n",
    "    model_rd_pc = o3d.geometry.PointCloud()\n",
    "    model_rd_pc.points = o3d.utility.Vector3dVector(np.asarray(model_rd.points))\n",
    "    rd_icp = icp_algorithm(model_rd_pc, model)\n",
    "    rd_icp_fitness.append(rd_icp.fitness)\n",
    "    rd_icp_inlier.append(rd_icp.inlier_rmse)\n",
    "\n",
    "    # voxel grid filter\n",
    "    model_voxel_grid = create_voxel_grid(model, 0.2)\n",
    "    model_voxel = voxel_filter(model, model_voxel_grid, 0.2)\n",
    "    vf_icp = icp_algorithm(model_voxel, model)\n",
    "    vf_icp_fitness.append(vf_icp.fitness)\n",
    "    vf_icp_inlier.append(rd_icp.inlier_rmse)\n",
    "\n",
    "    # farthest point downsampling#\n",
    "    model_fp = farthest_point_sampling(model, int(len(model.points) / 10 * 4))\n",
    "    model_fp_pc = o3d.geometry.PointCloud()\n",
    "    model_fp_pc.points = o3d.utility.Vector3dVector(np.asarray(model_fp.points))\n",
    "    fp_icp = icp_algorithm(model_fp_pc, model)\n",
    "    fp_icp_fitness.append(fp_icp.fitness)\n",
    "    fp_icp_inlier.append(fp_icp.inlier_rmse)\n",
    "\n",
    "write_csv(rd_icp_fitness, \"rd_icp_fitness.csv\")\n",
    "write_csv(vf_icp_fitness, \"vf_icp_fitness.csv\")\n",
    "write_csv(fp_icp_fitness, \"fp_icp_fitness.csv\")\n",
    "write_csv(rd_icp_inlier, \"rd_icp_inlier.csv\")\n",
    "write_csv(vf_icp_inlier, \"vf_icp_inlier.csv\")\n",
    "write_csv(fp_icp_inlier, \"fp_icp_inlier.csv\")"
   ],
   "id": "f2ae2791168b938f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Noisiness test basic models",
   "id": "b3915e0c231b90ca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T21:14:06.454055Z",
     "start_time": "2024-06-20T21:13:49.982549Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_array = [cube, cone, sphere]\n",
    "model_names = [\"cube\", \"cone\", \"sphere\"]\n",
    "for index, model in enumerate(model_array):\n",
    "    # create noisy pointclouds\n",
    "    noisy_model = add_noise(model, 0.1)\n",
    "\n",
    "    # Random Downsampling\n",
    "    rd_noisy = random_downsampling(noisy_model, int(len(noisy_model.points) / 10 * 4))\n",
    "    point_cloud_to_ply(rd_noisy, \"noisy_rd_\" + model_names[index - 1])\n",
    "\n",
    "    # Voxel Grid Filter\n",
    "    noisy_model_grid = create_voxel_grid(noisy_model, 0.2)\n",
    "    noisy_model_voxel_pc = voxel_filter(noisy_model, noisy_model_grid, 0.2)\n",
    "    point_cloud_to_ply(noisy_model_voxel_pc, \"noisy_vf_\" + model_names[index - 1])\n",
    "\n",
    "    # Farthest Point Downsampling\n",
    "    noisy_model_fp = farthest_point_sampling(noisy_model, int(len(noisy_model.points) / 10 * 4))\n",
    "    noisy_model_fp_pc = o3d.geometry.PointCloud()\n",
    "    noisy_model_fp_pc.points = o3d.utility.Vector3dVector(np.asarray(noisy_model_fp.points))\n",
    "    point_cloud_to_ply(noisy_model_fp_pc, \"noisy_fp_\" + model_names[index - 1])\n"
   ],
   "id": "8d66fc758daa7984",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[56], line 13\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m# Voxel Grid Filter\u001B[39;00m\n\u001B[0;32m     12\u001B[0m noisy_model_grid \u001B[38;5;241m=\u001B[39m create_voxel_grid(noisy_model, \u001B[38;5;241m0.2\u001B[39m)\n\u001B[1;32m---> 13\u001B[0m noisy_model_voxel_pc \u001B[38;5;241m=\u001B[39m \u001B[43mvoxel_filter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnoisy_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnoisy_model_grid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.2\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     14\u001B[0m point_cloud_to_ply(noisy_model_voxel_pc, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnoisy_vf_\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m model_names[index\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m])\n\u001B[0;32m     16\u001B[0m \u001B[38;5;66;03m# Farthest Point Downsampling\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[14], line 26\u001B[0m, in \u001B[0;36mvoxel_filter\u001B[1;34m(model, voxelgrid, voxel_size)\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;66;03m# iterate over all voxel in the voxelgrid\u001B[39;00m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m voxel \u001B[38;5;129;01min\u001B[39;00m voxelgrid\u001B[38;5;241m.\u001B[39mget_voxels():\n\u001B[0;32m     25\u001B[0m     \u001B[38;5;66;03m# get bounds of the voxel\u001B[39;00m\n\u001B[1;32m---> 26\u001B[0m     downsampled_points\u001B[38;5;241m.\u001B[39mextend(\u001B[43mis_point_in_voxel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvoxelgrid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvoxel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvoxel_size\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m     27\u001B[0m downsampled_points \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(downsampled_points)\n\u001B[0;32m     28\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m create_pointcloud_from_coordinates(downsampled_points)\n",
      "Cell \u001B[1;32mIn[14], line 47\u001B[0m, in \u001B[0;36mis_point_in_voxel\u001B[1;34m(model, voxelgrid, voxel, voxel_size)\u001B[0m\n\u001B[0;32m     45\u001B[0m \u001B[38;5;66;03m# check, which points are lying within a voxel\u001B[39;00m\n\u001B[0;32m     46\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m point \u001B[38;5;129;01min\u001B[39;00m model\u001B[38;5;241m.\u001B[39mpoints:\n\u001B[1;32m---> 47\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mall\u001B[49m(np\u001B[38;5;241m.\u001B[39mabs(point \u001B[38;5;241m-\u001B[39m voxel_center) \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m half_size):\n\u001B[0;32m     48\u001B[0m         points_in_voxel\u001B[38;5;241m.\u001B[39mappend(point)\n\u001B[0;32m     49\u001B[0m points_in_voxel \u001B[38;5;241m=\u001B[39m aggregate_points(points_in_voxel)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "noisiness tests complex models",
   "id": "4614eecfb0cb5f76"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T21:26:25.325506Z",
     "start_time": "2024-06-20T21:14:53.564058Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_array = [complex_sphere, complex_cube, complex_cone]\n",
    "model_names = [\"complex_sphere\", \"complex_cube\", \"complex_cone\"]\n",
    "\n",
    "for index, complex_model in enumerate(model_array):\n",
    "    noisy_complex_model = add_noise(complex_model, 1.3)\n",
    "    rd_complex_noisy = random_downsampling(noisy_complex_model, int(len(noisy_complex_model.points) / 10 * 4))\n",
    "    point_cloud_to_ply(rd_complex_noisy, \"noisy_rd_\" + model_names[index])\n",
    "\n",
    "    noisy_complex_model_grid = create_voxel_grid(noisy_complex_model, 0.2)\n",
    "    noisy_complex_model_voxel_pc = voxel_filter(noisy_complex_model, noisy_complex_model_grid, 0.2)\n",
    "    point_cloud_to_ply(noisy_complex_model_voxel_pc, \"noisy_vf_\" + model_names[index])\n",
    "\n",
    "    noisy_complex_model_fp = farthest_point_sampling(noisy_complex_model, int(len(noisy_complex_model.points) / 10 * 4))\n",
    "    noisy_complex_model_fp_pc = o3d.geometry.PointCloud()\n",
    "    noisy_complex_model_fp_pc.points = o3d.utility.Vector3dVector(np.asarray(noisy_complex_model_fp.points))\n",
    "    point_cloud_to_ply(noisy_complex_model_fp_pc, \"noisy_fp_\" + model_names[index])"
   ],
   "id": "c8bbfb52eaf0dd2d",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "noisiness tests objects",
   "id": "8a7a286ea5d1bbce"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-06-21T10:22:23.326487Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_array = [book, teapot, pencil]\n",
    "model_names = [\"book\", \"teapot\", \"pencil\"]\n",
    "\n",
    "for index, model_object in enumerate(model_array):\n",
    "    # random downsampling\n",
    "    noisy_model_object = add_noise(model_object, 0.1)\n",
    "    #rd_noisy = random_downsampling(noisy_model_object, int(len(noisy_model_object.points) / 10 * 4))\n",
    "    #point_cloud_to_ply(rd_noisy, \"noisy_rd_\" + model_names[index])\n",
    "\n",
    "    # voxel grid filter\n",
    "    noisy_model_object_grid = create_voxel_grid(noisy_model_object, 0.2)\n",
    "    noisy_object_voxel_pc = voxel_filter(noisy_model_object, noisy_model_object_grid, 0.2)\n",
    "    point_cloud_to_ply(noisy_object_voxel_pc, \"noisy_vf_\" + model_names[index])\n",
    "\n",
    "    # farthest point downsampling\n",
    "    noisy_model_object_fp = farthest_point_sampling(noisy_model_object, int(len(noisy_model_object.points) / 10 * 4))\n",
    "    noisy_model_object_fp_pc = o3d.geometry.PointCloud()\n",
    "    noisy_model_object_fp_pc.points = o3d.utility.Vector3dVector(np.asarray(noisy_model_object_fp.points))\n",
    "    point_cloud_to_ply(noisy_model_object_fp_pc, \"noisy_fp_\" + model_names[index])"
   ],
   "id": "979984132ccf6e65",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "DOWNSAMPLING SIMPLE AUFBAU",
   "id": "a13a509dd712e465"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T18:36:38.735286Z",
     "start_time": "2024-06-22T18:29:35.447086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_array = [cube, cone, sphere]\n",
    "model_names = [\"cube\", \"cone\", \"sphere\"]\n",
    "for index, model in enumerate(model_array):\n",
    "    # create noisy pointclouds\n",
    "    noisy_model = add_noise(model, 0.1)\n",
    "\n",
    "    # Random Downsampling\n",
    "    rd_noisy = random_downsampling(noisy_model, int(len(noisy_model.points) / 10 * 2))\n",
    "    point_cloud_to_ply_simple(rd_noisy, \"rd_\" + model_names[index - 1])\n",
    "\n",
    "    # Voxel Grid Filter\n",
    "    noisy_model_grid = create_voxel_grid(noisy_model, 0.6)\n",
    "    noisy_model_voxel_pc = voxel_filter(noisy_model, noisy_model_grid, 0.6)\n",
    "    point_cloud_to_ply_simple(noisy_model_voxel_pc, \"vf_\" + model_names[index - 1])\n",
    "\n",
    "    # Farthest Point Downsampling\n",
    "    noisy_model_fp = farthest_point_sampling(noisy_model, int(len(noisy_model.points) / 10 * 2))\n",
    "    noisy_model_fp_pc = o3d.geometry.PointCloud()\n",
    "    noisy_model_fp_pc.points = o3d.utility.Vector3dVector(np.asarray(noisy_model_fp.points))\n",
    "    point_cloud_to_ply_simple(noisy_model_fp_pc, \"fp_\" + model_names[index - 1])\n"
   ],
   "id": "d1c9b3e52f708bc8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Open3D WARNING] Write PLY failed: unable to open file: point_cloud_images_simple/rd_sphere.ply\n",
      "[Open3D WARNING] Write PLY failed: unable to open file: point_cloud_images_simple/vf_sphere.ply\n",
      "[Open3D WARNING] Write PLY failed: unable to open file: point_cloud_images_simple/fp_sphere.ply\n",
      "[Open3D WARNING] Write PLY failed: unable to open file: point_cloud_images_simple/rd_cube.ply\n",
      "[Open3D WARNING] Write PLY failed: unable to open file: point_cloud_images_simple/vf_cube.ply\n",
      "[Open3D WARNING] Write PLY failed: unable to open file: point_cloud_images_simple/fp_cube.ply\n",
      "[Open3D WARNING] Write PLY failed: unable to open file: point_cloud_images_simple/rd_cone.ply\n",
      "[Open3D WARNING] Write PLY failed: unable to open file: point_cloud_images_simple/vf_cone.ply\n",
      "[Open3D WARNING] Write PLY failed: unable to open file: point_cloud_images_simple/fp_cone.ply\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "14e3e710adefaee1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
