{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install open3d"
      ],
      "metadata": {
        "id": "f6Y6G9PFbr_A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "490a26f0-e940-4fc8-c037-7df888ad1cff"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting open3d\n",
            "  Downloading open3d-0.18.0-cp310-cp310-manylinux_2_27_x86_64.whl (399.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.7/399.7 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (1.25.2)\n",
            "Collecting dash>=2.6.0 (from open3d)\n",
            "  Downloading dash-2.17.1-py3-none-any.whl (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: werkzeug>=2.2.3 in /usr/local/lib/python3.10/dist-packages (from open3d) (3.0.3)\n",
            "Requirement already satisfied: nbformat>=5.7.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (5.10.4)\n",
            "Collecting configargparse (from open3d)\n",
            "  Downloading ConfigArgParse-1.7-py3-none-any.whl (25 kB)\n",
            "Collecting ipywidgets>=8.0.4 (from open3d)\n",
            "  Downloading ipywidgets-8.1.3-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting addict (from open3d)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: pillow>=9.3.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (9.4.0)\n",
            "Requirement already satisfied: matplotlib>=3 in /usr/local/lib/python3.10/dist-packages (from open3d) (3.7.1)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (2.0.3)\n",
            "Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from open3d) (6.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.21 in /usr/local/lib/python3.10/dist-packages (from open3d) (1.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from open3d) (4.66.4)\n",
            "Collecting pyquaternion (from open3d)\n",
            "  Downloading pyquaternion-0.9.9-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: Flask<3.1,>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (2.2.5)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (5.15.0)\n",
            "Collecting dash-html-components==2.0.0 (from dash>=2.6.0->open3d)\n",
            "  Downloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n",
            "Collecting dash-core-components==2.0.0 (from dash>=2.6.0->open3d)\n",
            "  Downloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n",
            "Collecting dash-table==5.0.0 (from dash>=2.6.0->open3d)\n",
            "  Downloading dash_table-5.0.0-py3-none-any.whl (3.9 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (7.2.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (4.12.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (2.31.0)\n",
            "Collecting retrying (from dash>=2.6.0->open3d)\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (1.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (67.7.2)\n",
            "Collecting comm>=0.1.3 (from ipywidgets>=8.0.4->open3d)\n",
            "  Downloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (5.7.1)\n",
            "Collecting widgetsnbextension~=4.0.11 (from ipywidgets>=8.0.4->open3d)\n",
            "  Downloading widgetsnbextension-4.0.11-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jupyterlab-widgets~=3.0.11 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (3.0.11)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (2.8.2)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.0->open3d) (2.20.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.0->open3d) (4.19.2)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.0->open3d) (5.7.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->open3d) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->open3d) (2024.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21->open3d) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21->open3d) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21->open3d) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=2.2.3->open3d) (2.1.5)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.6.0->open3d) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.6.0->open3d) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.6.0->open3d) (8.1.7)\n",
            "Collecting jedi>=0.16 (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.9.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.18.1)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=5.7.0->open3d) (4.2.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=5.0.0->dash>=2.6.0->open3d) (8.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3->open3d) (1.16.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->dash>=2.6.0->open3d) (3.19.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (2024.6.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.13)\n",
            "Installing collected packages: dash-table, dash-html-components, dash-core-components, addict, widgetsnbextension, retrying, pyquaternion, jedi, configargparse, comm, ipywidgets, dash, open3d\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.6\n",
            "    Uninstalling widgetsnbextension-3.6.6:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.6\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.7.1\n",
            "    Uninstalling ipywidgets-7.7.1:\n",
            "      Successfully uninstalled ipywidgets-7.7.1\n",
            "Successfully installed addict-2.4.0 comm-0.2.2 configargparse-1.7 dash-2.17.1 dash-core-components-2.0.0 dash-html-components-2.0.0 dash-table-5.0.0 ipywidgets-8.1.3 jedi-0.19.1 open3d-0.18.0 pyquaternion-0.9.9 retrying-1.3.4 widgetsnbextension-4.0.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Imports\n",
        "from io import BytesIO\n",
        "import time\n",
        "import csv\n",
        "import os\n",
        "import open3d as o3d\n",
        "import random\n",
        "import requests\n",
        "import tarfile\n",
        "import numpy as np\n",
        "from scipy.spatial import distance\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "#%%\n",
        "def gromov_wasserstein(pc1: np.ndarray, pc2: np.ndarray) -> float:\n",
        "    def dist_ecc_fast(ecc, u):\n",
        "        return (np.mean(ecc <= u))\n",
        "\n",
        "    out = 0\n",
        "    # convert point clouds to numpy arrays\n",
        "    pc1 = np.asarray(pc1.points)\n",
        "    pc2 = np.asarray(pc2.points)\n",
        "\n",
        "    # Reshape input matrices if necessary\n",
        "    if pc1.ndim == 1:\n",
        "        pc1 = pc1.reshape(-1, 1)\n",
        "    if pc2.ndim == 1:\n",
        "        pc2 = pc2.reshape(-1, 1)\n",
        "\n",
        "    ecc1 = squareform(pdist(pc1)).mean(0)\n",
        "    ecc2 = squareform(pdist(pc2)).mean(0)\n",
        "    unique_ecc = np.unique(np.concatenate((ecc1, ecc2)))\n",
        "    for i in range(unique_ecc.shape[0] - 1):\n",
        "        u = unique_ecc[i]\n",
        "        out += (unique_ecc[i + 1] - unique_ecc[i]) * np.abs(dist_ecc_fast(ecc1, u) - dist_ecc_fast(ecc2, u))\n",
        "\n",
        "    return (0.5 * out)\n",
        "#%%\n",
        "def create_pcd_from_mesh(mesh):\n",
        "    mesh.compute_vertex_normals()\n",
        "    o3d.visualization.draw_geometries([mesh])\n",
        "    # distribute dots evenly on the surface\n",
        "    return mesh.sample_points_uniformly(500)\n",
        "#%%\n",
        "def load_model(link, path):\n",
        "    # http://ycb-benchmarks.s3-website-us-east-1.amazonaws.com/\n",
        "    response = requests.get(link)\n",
        "    tgz_data = BytesIO(response.content)\n",
        "    # set the current working directory to the script's directory\n",
        "    script_directory = os.path.dirname(os.path.abspath(__file__))\n",
        "    os.chdir(script_directory)\n",
        "    with tarfile.open(fileobj=tgz_data, mode=\"r:gz\") as tar_ref:\n",
        "        tar_ref.extractall(script_directory)\n",
        "    # join paths\n",
        "    model_path = os.path.join(script_directory, path, \"clouds\", \"merged_cloud.ply\")\n",
        "    # load pointcloud\n",
        "    pcd = o3d.io.read_point_cloud(model_path)\n",
        "    return pcd\n",
        "#%%\n",
        "def load_cad_model(model):\n",
        "    # load model generated in freecad\n",
        "    return o3d.io.read_point_cloud(model)\n",
        "#%%\n",
        "def visualize_model(model):\n",
        "    o3d.visualization.draw_geometries([model])\n",
        "#%%\n",
        "def get_num_points(model):\n",
        "    print(len(model.points))\n",
        "#%%\n",
        "def create_pointcloud_from_coordinates(coordinates):\n",
        "    # create point cloud with coordinates\n",
        "    pcd = o3d.geometry.PointCloud()\n",
        "    pcd.points = o3d.utility.Vector3dVector(coordinates)\n",
        "    return pcd\n",
        "#%%\n",
        "def get_coordinates(model):\n",
        "    coordinates = [list(point) for point in model.points]\n",
        "    # print(coordinates[:50])\n",
        "    return coordinates\n",
        "#%%\n",
        "def random_downsampling(model, endpoints):\n",
        "    # get coordinates of the models\n",
        "    coordinates = get_coordinates(model)\n",
        "    # select random points for downsampling\n",
        "    for i in range(len(coordinates) - endpoints):\n",
        "        rannumb = random.randint(0, len(coordinates) - 1)\n",
        "        del coordinates[rannumb]\n",
        "    point_cloud = create_pointcloud_from_coordinates(coordinates)\n",
        "    return point_cloud\n",
        "#%%\n",
        "def farthest_point_sampling(model, num_points_keep):\n",
        "    coordinates = np.array(get_coordinates(model))\n",
        "    retVal = []\n",
        "    # to make runs comparable\n",
        "    random.seed(13)\n",
        "    # generate \"random\" int\n",
        "    randint = random.randint(0, len(coordinates) - 1)\n",
        "    # select random point from model\n",
        "    retVal.append(coordinates[randint])\n",
        "    # delete chosen point from original model after it was added to the downsampled cloud\n",
        "    coordinates = np.delete(coordinates, randint, axis=0)\n",
        "    while len(retVal) < num_points_keep:\n",
        "        # Berechne die euklidischen Distanzen der ausgewählten Punkte zu den verbleibenden Punkten\n",
        "        eucl_distances = distance.cdist(retVal, coordinates, 'euclidean')\n",
        "        # Find point with largest min Distance\n",
        "        min_mindist = np.min(eucl_distances, axis=0)\n",
        "        # Find index of point with largest min DIstance\n",
        "        max_min_distance_index = np.argmax(min_mindist)\n",
        "        # add point that is farthest away\n",
        "        retVal.append(coordinates[max_min_distance_index])\n",
        "        # delete point from coordinates list\n",
        "        coordinates = np.delete(coordinates, max_min_distance_index, axis=0)\n",
        "    return create_pointcloud_from_coordinates(np.array(retVal))\n",
        "#%%\n",
        "# built in function von open3d\n",
        "def radius_outlier_removal_call(model):\n",
        "    return model.remove_radius_outlier(nb_points=5, radius=0.05)\n",
        "#%%\n",
        "# add noise to pointcloud\n",
        "def add_noise(model, noise_value):\n",
        "    points = np.asarray(model.points)\n",
        "    noise = np.random.normal(0, noise_value, size=points.shape)\n",
        "    noisy_points = points + noise\n",
        "\n",
        "    noisy_pc = o3d.geometry.PointCloud()\n",
        "    noisy_pc.points = o3d.utility.Vector3dVector(noisy_points)\n",
        "    return noisy_pc\n",
        "#%%\n",
        "def create_voxel_grid(model, voxel_size):\n",
        "    model_points = np.array(get_coordinates(model))\n",
        "    min_bound = np.min(model_points, axis=0)\n",
        "    max_bound = np.max(model_points, axis=0)\n",
        "\n",
        "    dimensions = np.ceil((max_bound - min_bound) / voxel_size).astype(int)\n",
        "\n",
        "    voxelgrid = np.zeros(dimensions)\n",
        "\n",
        "    for point in model_points:\n",
        "        voxel_coordinates = ((point - min_bound) / voxel_size).astype(int)\n",
        "        # -1 needed in order to avoid index out of bounds\n",
        "        voxelgrid[tuple(voxel_coordinates - 1)] += 1\n",
        "    # convert voxelgrid to open3d Voxelgrid\n",
        "    o3d_voxelgrid = o3d.geometry.VoxelGrid.create_from_point_cloud(input=model, voxel_size=voxel_size)\n",
        "    #o3d.visualization.draw_geometries([o3d_voxelgrid])\n",
        "    return o3d_voxelgrid\n",
        "\n",
        "\n",
        "def voxel_filter(model, voxelgrid, voxel_size):\n",
        "    # list where downsampled points will be saved\n",
        "    downsampled_points = []\n",
        "    # iterate over all voxel in the voxelgrid\n",
        "    for voxel in voxelgrid.get_voxels():\n",
        "        # get bounds of the voxel\n",
        "        downsampled_points.extend(is_point_in_voxel(model, voxelgrid, voxel, voxel_size))\n",
        "    downsampled_points = np.asarray(downsampled_points)\n",
        "    return create_pointcloud_from_coordinates(downsampled_points)\n",
        "\n",
        "\n",
        "def aggregate_points(points):\n",
        "    # Aggregate the points by averaging, taking into account the z coordinate\n",
        "    if len(points) == 0:\n",
        "        return points\n",
        "    aggregated_points = []\n",
        "    aggregated_points.append(np.mean(points, axis=0))\n",
        "    return aggregated_points\n",
        "\n",
        "\n",
        "def is_point_in_voxel(model, voxelgrid, voxel, voxel_size):\n",
        "    # get center point and see whether a point lies within the given distance/2 of the voxel size from the center\n",
        "    voxel_center = voxelgrid.get_voxel_center_coordinate(voxel.grid_index)\n",
        "    points_in_voxel = []\n",
        "    half_size = voxel_size / 2.0\n",
        "    # check, which points are lying within a voxel\n",
        "    for point in model.points:\n",
        "        if np.all(np.abs(point - voxel_center) <= half_size):\n",
        "            points_in_voxel.append(point)\n",
        "    points_in_voxel = aggregate_points(points_in_voxel)\n",
        "    # print(points_in_voxel)\n",
        "    return points_in_voxel\n",
        "\n",
        "\n",
        "def create_points_from_voxel(voxel_model):\n",
        "    # convert vector in numpy array\n",
        "    vector_array = np.asarray(voxel_model)\n",
        "\n",
        "    # create o3d point cloud\n",
        "    point_cloud = o3d.geometry.PointCloud()\n",
        "    point_cloud.points = o3d.utility.Vector3dVector(vector_array)\n",
        "\n",
        "    return point_cloud\n",
        "\n",
        "#%%\n",
        "def point_cloud_to_ply(point_cloud, file_name):\n",
        "    # safe downsampled point cloud as ply data\n",
        "    #file_name = \"point_cloud_images/\" + file_name + \".ply\"\n",
        "    file_name = file_name + \".ply\"\n",
        "    #if os.path.exists(\"point_cloud_images/\" + file_name):\n",
        "    #    os.remove(file_name)\n",
        "    if os.path.exists(file_name):\n",
        "        os.remove(file_name)\n",
        "    o3d.io.write_point_cloud(file_name, o3d.geometry.PointCloud(point_cloud.points))\n",
        "\n",
        "#%%\n",
        "cone = load_cad_model(r\"/cone.ply\")\n",
        "sphere = load_cad_model(r\"/sphere.ply\")\n",
        "cube = load_cad_model(r\"/cube.ply\")\n",
        "complex_cube = load_cad_model(r\"/complexCube.ply\")\n",
        "complex_cone = load_cad_model(r\"/hollowCone.ply\")\n",
        "complex_sphere = load_cad_model(r\"/complexSphere.ply\")\n",
        "pencil = load_cad_model(r\"/pencil_fein.ply\")\n",
        "# source: https://sketchfab.com/3d-models/davis-teapot-materialcleanup-547971eaf21d43f2b6cfcb6be0e7bf11\n",
        "teapot = load_cad_model(r\"/teapot.ply\")\n",
        "# source: https://sketchfab.com/3d-models/book-ba04f5ac66194341bc7d437fb6c94674\n",
        "book = load_cad_model(r\"/book.ply\")\n",
        "#%%\n",
        "def icp_algorithm(source, target):\n",
        "    # transform target point cloud\n",
        "    transformation = np.array([[0.86, 0.5, 0.1, 0.5],\n",
        "                               [-0.5, 0.86, 0.1, 0.99],\n",
        "                               [0.0, -0.1, 0.99, 0.5],\n",
        "                               [1.3, 0.0, 0.0, 1.0]])\n",
        "    target = target.transform(transformation)\n",
        "\n",
        "    threshold = 0.25  # max distance for deleting points\n",
        "    initial_transformation = np.identity(4)  # initial guess of transformation\n",
        "\n",
        "    # Open3D ICP Algorithmus\n",
        "    reg_p2p = o3d.pipelines.registration.registration_icp(\n",
        "        source, target, threshold, initial_transformation,\n",
        "        o3d.pipelines.registration.TransformationEstimationPointToPoint())\n",
        "    source.transform(reg_p2p.transformation)\n",
        "    return reg_p2p\n",
        "\n",
        "#%%\n",
        "def write_csv(array, filename):\n",
        "    # Öffne die CSV-Datei im Schreibmodus\n",
        "    with open(filename, mode='w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        for row in array:\n",
        "            writer.writerow([row])\n",
        "#%%"
      ],
      "metadata": {
        "id": "cWg76JwglgE6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "rd_wasserstein = []\n",
        "vf_wasserstein = []\n",
        "fp_wasserstein = []\n",
        "\n",
        "num_iterations = 25\n",
        "model_array = [cone]\n",
        "array_noise = [0.05, 0.2, 1]\n",
        "for model in model_array:\n",
        "    for noise in array_noise:\n",
        "        for i in range(num_iterations):\n",
        "            model = add_noise(model, noise)\n",
        "\n",
        "            #random downsampling\n",
        "            rd = random_downsampling(model, int(len(model.points) / 10 * 0.2))\n",
        "\n",
        "            # voxelgrid\n",
        "            vx_grid = create_voxel_grid(model, 8.5)\n",
        "            vx = voxel_filter(model, vx_grid, 8.5)\n",
        "\n",
        "            # farthest point downsampling\n",
        "            fp = farthest_point_sampling(model, int(len(model.points) / 10 * 0.2))\n",
        "\n",
        "            # Random Downsampling\n",
        "            rd_wasserstein.append(gromov_wasserstein(rd, model))\n",
        "            # Voxelgrid Filter\n",
        "            vf_wasserstein.append(gromov_wasserstein(vx, model))\n",
        "            # Farthest Point Downsampling\n",
        "            fp_wasserstein.append(gromov_wasserstein(fp, model))\n",
        "\n",
        "write_csv(rd_wasserstein, \"rd_wasserstein.csv\")\n",
        "write_csv(vf_wasserstein, \"vf_wasserstein.csv\")\n",
        "write_csv(fp_wasserstein, \"fp_wasserstein.csv\")\n",
        "\n",
        "#%%\n"
      ],
      "metadata": {
        "id": "g7lbGhU47E2x"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rd_times = []  # List of lists for random downsampling times\n",
        "vf_times = []  # List of lists for voxel filter times\n",
        "fp_times = []  # List of lists for farthest point sampling times\n",
        "\n",
        "num_iterations = 10\n",
        "\n",
        "# Methode Spalte, Modell Zeile ?\n",
        "# [][][]\n",
        "# [][][]\n",
        "model_array = [cone]\n",
        "for i, model in enumerate(model_array):\n",
        "    for round in range(num_iterations):\n",
        "        # random downsampling\n",
        "        start = time.time()\n",
        "        rd = random_downsampling(model, int(len(model.points) / 10 * 0.2))\n",
        "        end = time.time()\n",
        "        elapsed_time = end - start\n",
        "        rd_times.append(elapsed_time)\n",
        "\n",
        "        # voxelgrid filter\n",
        "        start = time.time()\n",
        "        vx_grid = create_voxel_grid(model, 8.5)\n",
        "        vx = voxel_filter(model, vx_grid, 8.5)\n",
        "        end = time.time()\n",
        "        elapsed_time = end - start\n",
        "        vf_times.append(elapsed_time)\n",
        "\n",
        "        # farthest point downsampling\n",
        "        start = time.time()\n",
        "        fp = farthest_point_sampling(model, int(len(model.points) / 10 * 0.2))\n",
        "        end = time.time()\n",
        "        fp_pc = o3d.geometry.PointCloud()\n",
        "        fp_pc.points = o3d.utility.Vector3dVector(np.asarray(fp.points))\n",
        "        elapsed_time = end - start\n",
        "        fp_times.append(elapsed_time)  # Add the time to the corresponding model's list\n",
        "\n",
        "write_csv(rd_times, \"rd_times.csv\")\n",
        "write_csv(vf_times, \"vf_times.csv\")\n",
        "write_csv(fp_times, \"fp_times.csv\")\n",
        "#%%\n"
      ],
      "metadata": {
        "id": "-QNGchN17OJr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vergleich auf den Originalwolken\n",
        "original_fitness = []\n",
        "original_inlier = []\n",
        "original_icp_time = []\n",
        "\n",
        "\n",
        "model_array = [cone]\n",
        "\n",
        "for model in model_array:\n",
        "    # ICP auf den Originalpunktewolken\n",
        "    start = time.time()\n",
        "    org_icp = icp_algorithm(model, model)\n",
        "    end = time.time()\n",
        "    original_icp_time.append(end - start)\n",
        "    original_fitness.append(org_icp.fitness)\n",
        "    original_inlier.append(org_icp.inlier_rmse)\n",
        "\n",
        "write_csv(original_inlier, \"original_icp_inlier.csv\")\n",
        "write_csv(original_fitness, \"original_icp_fitness.csv\")\n",
        "write_csv(original_icp_time, \"original_icp_time.csv\")\n",
        "\n",
        "#%%\n"
      ],
      "metadata": {
        "id": "QHjudfpt8CgS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rd_icp_fitness = []\n",
        "rd_icp_inlier = []\n",
        "vf_icp_fitness = []\n",
        "vf_icp_inlier = []\n",
        "fp_icp_fitness = []\n",
        "fp_icp_inlier = []\n",
        "fp_icp_time = []\n",
        "vf_icp_time = []\n",
        "rd_icp_time = []\n",
        "\n",
        "\n",
        "\n",
        "model_array = [cone]\n",
        "\n",
        "\n",
        "for model in model_array:\n",
        "    # random downsampling\n",
        "    model_rd = random_downsampling(model, int(len(model.points) / 10 * 0.2))\n",
        "    model_rd_pc = o3d.geometry.PointCloud()\n",
        "    model_rd_pc.points = o3d.utility.Vector3dVector(np.asarray(model_rd.points))\n",
        "    start = time.time()\n",
        "    rd_icp = icp_algorithm(model_rd_pc, model)\n",
        "    end = time.time()\n",
        "    rd_icp_fitness.append(rd_icp.fitness)\n",
        "    rd_icp_inlier.append(rd_icp.inlier_rmse)\n",
        "    rd_icp_time.append(end - start)\n",
        "    #model_transformed = model.transform(rd_icp.transformation)\n",
        "\n",
        "    # show source and source and target\n",
        "    #o3d.visualization.draw_geometries([model, model_transformed])\n",
        "\n",
        "    # voxel grid filter\n",
        "    model_voxel_grid = create_voxel_grid(model, 8.5)\n",
        "    model_voxel = voxel_filter(model, model_voxel_grid, 8.5)\n",
        "    start = time.time()\n",
        "    vf_icp = icp_algorithm(model_voxel, model)\n",
        "    end = time.time()\n",
        "    vf_icp_time.append(end - start)\n",
        "    vf_icp_fitness.append(vf_icp.fitness)\n",
        "    vf_icp_inlier.append(vf_icp.inlier_rmse)\n",
        "    #model_transformed = model.transform(vf_icp.transformation)\n",
        "\n",
        "    # show source and source and target\n",
        "    #o3d.visualization.draw_geometries([model, model_transformed])\n",
        "\n",
        "    # farthest point downsampling#\n",
        "    model_fp = farthest_point_sampling(model, int(len(model.points) / 10 * 0.2))\n",
        "    model_fp_pc = o3d.geometry.PointCloud()\n",
        "    model_fp_pc.points = o3d.utility.Vector3dVector(np.asarray(model_fp.points))\n",
        "    start = time.time()\n",
        "    fp_icp = icp_algorithm(model_fp_pc, model)\n",
        "    end = time.time()\n",
        "    fp_icp_time.append(end - start)\n",
        "    fp_icp_fitness.append(fp_icp.fitness)\n",
        "    fp_icp_inlier.append(fp_icp.inlier_rmse)\n",
        "    #model_transformed = model.transform(fp_icp.transformation)\n",
        "\n",
        "    # show source and source and target\n",
        "    #o3d.visualization.draw_geometries([model, model_transformed])\n",
        "\n",
        "write_csv(rd_icp_fitness, \"rd_icp_fitness.csv\")\n",
        "write_csv(vf_icp_fitness, \"vf_icp_fitness.csv\")\n",
        "write_csv(fp_icp_fitness, \"fp_icp_fitness.csv\")\n",
        "write_csv(rd_icp_inlier, \"rd_icp_inlier.csv\")\n",
        "write_csv(vf_icp_inlier, \"vf_icp_inlier.csv\")\n",
        "write_csv(fp_icp_inlier, \"fp_icp_inlier.csv\")\n",
        "write_csv(rd_icp_time, \"rd_icp_time.csv\")\n",
        "write_csv(vf_icp_time, \"vf_icp_time.csv\")\n",
        "write_csv(fp_icp_time, \"fp_icp_time.csv\")\n",
        "#%%\n"
      ],
      "metadata": {
        "id": "Za-_Qt0t8Lfy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_array = [cube, cone, sphere]\n",
        "model_names = [\"cube\", \"cone\", \"sphere\"]\n",
        "for index, model in enumerate(model_array):\n",
        "    # create noisy pointclouds\n",
        "    noisy_model = add_noise(model, 1.3)\n",
        "\n",
        "    # Random Downsampling\n",
        "    rd_noisy = random_downsampling(noisy_model, int(len(noisy_model.points) / 10 * 0.2))\n",
        "    point_cloud_to_ply(rd_noisy, \"noisy_rd_\" + model_names[index - 1])\n",
        "\n",
        "    # Voxel Grid Filter\n",
        "    noisy_model_grid = create_voxel_grid(noisy_model, 8.5)\n",
        "    noisy_model_voxel_pc = voxel_filter(noisy_model, noisy_model_grid, 8.5)\n",
        "    point_cloud_to_ply(noisy_model_voxel_pc, \"noisy_vf_\" + model_names[index - 1])\n",
        "\n",
        "    # Farthest Point Downsampling\n",
        "    noisy_model_fp = farthest_point_sampling(noisy_model, int(len(noisy_model.points) / 10 * 0.2))\n",
        "    noisy_model_fp_pc = o3d.geometry.PointCloud()\n",
        "    noisy_model_fp_pc.points = o3d.utility.Vector3dVector(np.asarray(noisy_model_fp.points))\n",
        "    point_cloud_to_ply(noisy_model_fp_pc, \"noisy_fp_\" + model_names[index - 1])\n",
        "\n",
        "#%%\n",
        "model_array = [complex_sphere, complex_cube, complex_cone]\n",
        "model_names = [\"complex_sphere\", \"complex_cube\", \"complex_cone\"]\n",
        "\n",
        "for index, complex_model in enumerate(model_array):\n",
        "    noisy_complex_model = add_noise(complex_model, 1.3)\n",
        "    rd_complex_noisy = random_downsampling(noisy_complex_model, int(len(noisy_complex_model.points) / 10 * 0.2))\n",
        "    point_cloud_to_ply(rd_complex_noisy, \"noisy_rd_\" + model_names[index])\n",
        "\n",
        "    noisy_complex_model_grid = create_voxel_grid(noisy_complex_model, 8.5)\n",
        "    noisy_complex_model_voxel_pc = voxel_filter(noisy_complex_model, noisy_complex_model_grid, 8.5)\n",
        "    point_cloud_to_ply(noisy_complex_model_voxel_pc, \"noisy_vf_\" + model_names[index])\n",
        "\n",
        "    noisy_complex_model_fp = farthest_point_sampling(noisy_complex_model, int(len(noisy_complex_model.points) / 10 * 0.2))\n",
        "    noisy_complex_model_fp_pc = o3d.geometry.PointCloud()\n",
        "    noisy_complex_model_fp_pc.points = o3d.utility.Vector3dVector(np.asarray(noisy_complex_model_fp.points))\n",
        "    point_cloud_to_ply(noisy_complex_model_fp_pc, \"noisy_fp_\" + model_names[index])\n",
        "#%%\n",
        "\n"
      ],
      "metadata": {
        "id": "6WNZTiZU8P8Z"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_array = [book, teapot, pencil]\n",
        "model_names = [\"book\", \"teapot\", \"pencil\"]\n",
        "\n",
        "for index, model_object in enumerate(model_array):\n",
        "    # random downsampling\n",
        "    noisy_model_object = add_noise(model_object, 1.3)\n",
        "    rd_noisy = random_downsampling(noisy_model_object, int(len(noisy_model_object.points) / 10 * 0.2))\n",
        "    point_cloud_to_ply(rd_noisy, \"noisy_rd_\" + model_names[index])\n",
        "\n",
        "    # voxel grid filter\n",
        "    noisy_model_object_grid = create_voxel_grid(noisy_model_object, 8.5)\n",
        "    noisy_object_voxel_pc = voxel_filter(noisy_model_object, noisy_model_object_grid, 8.5)\n",
        "    point_cloud_to_ply(noisy_object_voxel_pc, \"noisy_vf_\" + model_names[index])\n",
        "\n",
        "    # farthest point downsampling\n",
        "    noisy_model_object_fp = farthest_point_sampling(noisy_model_object, int(len(noisy_model_object.points) / 10 * 0.2))\n",
        "    noisy_model_object_fp_pc = o3d.geometry.PointCloud()\n",
        "    noisy_model_object_fp_pc.points = o3d.utility.Vector3dVector(np.asarray(noisy_model_object_fp.points))\n",
        "    point_cloud_to_ply(noisy_model_object_fp_pc, \"noisy_fp_\" + model_names[index])\n",
        "#%%\n"
      ],
      "metadata": {
        "id": "20KQSat_Iv1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#buch wieder hinzufügen!\n",
        "model_array = [cube, cone, sphere, complex_sphere, complex_cube, complex_cone, teapot, pencil]\n",
        "model_names = [\"cube\", \"cone\", \"sphere\", \"complex_sphere\", \"complex_cube\", \"complex_cone\", \"teapot\", \"pencil\"]\n",
        "\n",
        "for index, model in enumerate(model_array):\n",
        "\n",
        "    # Random Downsampling\n",
        "    rd = random_downsampling(model, int(len(model.points) / 10 * 0.2))\n",
        "    point_cloud_to_ply(rd, \"rd_\" + model_names[index - 1])\n",
        "\n",
        "    # Voxel Grid Filter\n",
        "    model_grid = create_voxel_grid(model, 8.5)\n",
        "    model_voxel_pc = voxel_filter(model, model_grid, 8.5)\n",
        "    point_cloud_to_ply(model_voxel_pc, \"vf_\" + model_names[index - 1])\n",
        "\n",
        "    # Farthest Point Downsampling\n",
        "    model_fp = farthest_point_sampling(model, int(len(model.points) / 10 * 0.2))\n",
        "    model_fp_pc = o3d.geometry.PointCloud()\n",
        "    model_fp_pc.points = o3d.utility.Vector3dVector(np.asarray(model_fp.points))\n",
        "    point_cloud_to_ply(model_fp_pc, \"fp_\" + model_names[index - 1])\n",
        "\n",
        "#%%"
      ],
      "metadata": {
        "id": "9m8udcriI2Oj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_array = [book]\n",
        "model_names = [\"book\"]\n",
        "\n",
        "for index, model in enumerate(model_array):\n",
        "\n",
        "    # Farthest Point Downsampling\n",
        "    model_fp = farthest_point_sampling(model, int(len(model.points) / 10 * 0.2))\n",
        "    model_fp_pc = o3d.geometry.PointCloud()\n",
        "    model_fp_pc.points = o3d.utility.Vector3dVector(np.asarray(model_fp.points))\n",
        "    point_cloud_to_ply(model_fp_pc, \"fp_\" + model_names[index - 1])\n",
        "\n",
        "#%%"
      ],
      "metadata": {
        "id": "QGOFbv4w-c7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "jDyxjZZx8blm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/My Drive/my_file.txt', 'w') as f:\n",
        "  f.write('Hello Google Drive!')"
      ],
      "metadata": {
        "id": "Gzqs52LX8ds8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotten der Laufzeit Tests"
      ],
      "metadata": {
        "id": "xMiYzIZGvTlG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data1 = pd.read_csv(r\"fp_times.csv\")\n",
        "data2 = pd.read_csv(r\"vf_times.csv\")\n",
        "data3 = pd.read_csv(r\"rd_times.csv\")\n",
        "\n",
        "data_list = [data1['Time'], data2['Time'], data3['Time']]\n",
        "labels = ['Random Downsampling', 'Voxel Grid Filter', 'Farthest Point Downsampling']\n",
        "\n",
        "# Erstellen des Boxplots\n",
        "plt.boxplot(data_list, patch_artist=True, showmeans=True, labels=labels)\n",
        "\n",
        "# Plot anpassen\n",
        "plt.title('Boxplot for times of downsampling methods')\n",
        "plt.xlabel('methods')\n",
        "plt.ylabel('times')\n",
        "plt.grid(True)  # Gitter anzeigen (optional)\n",
        "\n",
        "# Plot anzeigen\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZRr-YQ1KuMO-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}